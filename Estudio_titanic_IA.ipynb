{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  zipfile import ZipFile\n",
    "from matplotlib import pyplot as plt\n",
    "# import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEMMA (SAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodolog√≠a CRISPDM (Cross Industry Standard Process for Data Mining)\n",
    "\n",
    "<img src='CRISPDM.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link competencia\n",
    "#### https://www.kaggle.com/competitions/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip0=ZipFile(\"titanic.zip\",mode='r')\n",
    "zip0.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.699118\n",
       "std       14.526497\n",
       "min        0.420000\n",
       "25%       20.125000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_df['Age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Age'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(train_df['Fare'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_df['Fare'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                          1\n",
       "Survived                             0\n",
       "Pclass                               3\n",
       "Name           Braund, Mr. Owen Harris\n",
       "Sex                               male\n",
       "Age                               22.0\n",
       "SibSp                                1\n",
       "Parch                                0\n",
       "Ticket                       A/5 21171\n",
       "Fare                              7.25\n",
       "Cabin                              NaN\n",
       "Embarked                             S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSIN VAlUES PERCENTAGE\n",
      "('PassengerId', 0.0)\n",
      "('Survived', 0.0)\n",
      "('Pclass', 0.0)\n",
      "('Name', 0.0)\n",
      "('Sex', 0.0)\n",
      "('Age', 0.19865319865319866)\n",
      "('SibSp', 0.0)\n",
      "('Parch', 0.0)\n",
      "('Ticket', 0.0)\n",
      "('Fare', 0.0)\n",
      "('Cabin', 0.7710437710437711)\n",
      "('Embarked', 0.002244668911335578)\n"
     ]
    }
   ],
   "source": [
    "print(\"MISSIN VAlUES PERCENTAGE\")\n",
    "for i in enumerate(train_df.columns):\n",
    "    print((i[1],sum(train_df[i[1]].isnull())/len(train_df[i[1]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caracter√≠sticas de los datos de Titanic\n",
    "\n",
    "<img src='titanic_notes.png'>\n",
    "\n",
    "\n",
    "\n",
    "<img src='tinanic_notes_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLenado de AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_FILLER=train_df[['Sex','Age','Pclass','Parch','Embarked']].groupby(['Sex','Pclass','Parch','Embarked']).agg({'Age':np.nanmean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"29\" valign=\"top\">female</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>C</th>\n",
       "      <td>36.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>34.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>C</th>\n",
       "      <td>40.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>37.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>C</th>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>22.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>C</th>\n",
       "      <td>21.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>33.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>S</th>\n",
       "      <td>24.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>C</th>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>22.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>S</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>C</th>\n",
       "      <td>14.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>19.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>26.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>C</th>\n",
       "      <td>11.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>16.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>C</th>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>13.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>C</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>S</th>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>Q</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>39.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>S</th>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"25\" valign=\"top\">male</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>C</th>\n",
       "      <td>39.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>43.740385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>C</th>\n",
       "      <td>43.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>45.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>C</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>14.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>S</th>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>C</th>\n",
       "      <td>30.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>33.554054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>C</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>17.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>C</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>24.443333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>C</th>\n",
       "      <td>27.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>28.586111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>C</th>\n",
       "      <td>13.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>12.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>16.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>S</th>\n",
       "      <td>10.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>S</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>S</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>S</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Age\n",
       "Sex    Pclass Parch Embarked           \n",
       "female 1      0     C         36.607143\n",
       "                    Q         33.000000\n",
       "                    S         34.960000\n",
       "              1     C         40.571429\n",
       "                    S         37.444444\n",
       "              2     C         20.333333\n",
       "                    S         22.800000\n",
       "       2      0     C         21.800000\n",
       "                    Q         30.000000\n",
       "                    S         33.500000\n",
       "              1     S         24.666667\n",
       "              2     C         12.500000\n",
       "                    S         22.222222\n",
       "              3     S         39.000000\n",
       "       3      0     C         14.750000\n",
       "                    Q         19.687500\n",
       "                    S         26.275000\n",
       "              1     C         11.785714\n",
       "                    Q         32.000000\n",
       "                    S         16.769231\n",
       "              2     C         15.000000\n",
       "                    Q               NaN\n",
       "                    S         13.312500\n",
       "              3     C         24.000000\n",
       "                    S         48.000000\n",
       "              4     S         37.000000\n",
       "              5     Q         39.000000\n",
       "                    S         39.333333\n",
       "              6     S         43.000000\n",
       "male   1      0     C         39.880000\n",
       "                    Q         44.000000\n",
       "                    S         43.740385\n",
       "              1     C         43.125000\n",
       "                    S         45.333333\n",
       "              2     C         34.000000\n",
       "                    S         14.184000\n",
       "              4     S         64.000000\n",
       "       2      0     C         30.100000\n",
       "                    Q         57.000000\n",
       "                    S         33.554054\n",
       "              1     C         31.000000\n",
       "                    S         17.115385\n",
       "              2     C         13.000000\n",
       "                    S         24.443333\n",
       "       3      0     C         27.285714\n",
       "                    Q         37.000000\n",
       "                    S         28.586111\n",
       "              1     C         13.105000\n",
       "                    Q         12.200000\n",
       "                    S         16.944444\n",
       "              2     S         10.884615\n",
       "              3     S         16.000000\n",
       "              4     S         40.000000\n",
       "              5     S         39.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGE_FILLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_=train_df.merge(right=AGE_FILLER,how='left',left_on=['Sex','Pclass','Parch','Embarked'],right_on=['Sex','Pclass','Parch','Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46943/4285108116.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resp_['Age_x'][resp_['Age_x'].isna()==True]=resp_['Age_y'][resp_['Age_x'].isna()==True]\n",
      "/tmp/ipykernel_46943/4285108116.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resp_['Age_x'][resp_['Age_x'].isna()==True]=-1\n"
     ]
    }
   ],
   "source": [
    "resp_['Age_x'][resp_['Age_x'].isna()==True]=resp_['Age_y'][resp_['Age_x'].isna()==True]\n",
    "resp_['Age_x'][resp_['Age_x'].isna()==True]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age_x</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>28.586111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>36.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>26.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>34.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>28.586111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>33.554054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>34.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>13.3125</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>39.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex    Age_x  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0000   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0000   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0000   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0000   \n",
       "4                             Allen, Mr. William Henry    male  35.0000   \n",
       "..                                                 ...     ...      ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0000   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0000   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  13.3125   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0000   \n",
       "890                                Dooley, Mr. Patrick    male  32.0000   \n",
       "\n",
       "     SibSp  Parch            Ticket     Fare Cabin Embarked      Age_y  \n",
       "0        1      0         A/5 21171   7.2500   NaN        S  28.586111  \n",
       "1        1      0          PC 17599  71.2833   C85        C  36.607143  \n",
       "2        0      0  STON/O2. 3101282   7.9250   NaN        S  26.275000  \n",
       "3        1      0            113803  53.1000  C123        S  34.960000  \n",
       "4        0      0            373450   8.0500   NaN        S  28.586111  \n",
       "..     ...    ...               ...      ...   ...      ...        ...  \n",
       "886      0      0            211536  13.0000   NaN        S  33.554054  \n",
       "887      0      0            112053  30.0000   B42        S  34.960000  \n",
       "888      1      2        W./C. 6607  23.4500   NaN        S  13.312500  \n",
       "889      0      0            111369  30.0000  C148        C  39.880000  \n",
       "890      0      0            370376   7.7500   NaN        Q  37.000000  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=resp_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PassengerId', dtype('int64'))\n",
      "('Survived', dtype('int64'))\n",
      "('Pclass', dtype('int64'))\n",
      "('Name', dtype('O'))\n",
      "('Sex', dtype('O'))\n",
      "('Age_x', dtype('float64'))\n",
      "('SibSp', dtype('int64'))\n",
      "('Parch', dtype('int64'))\n",
      "('Ticket', dtype('O'))\n",
      "('Fare', dtype('float64'))\n",
      "('Cabin', dtype('O'))\n",
      "('Embarked', dtype('O'))\n",
      "('Age_y', dtype('float64'))\n"
     ]
    }
   ],
   "source": [
    "for i in train_df.columns:\n",
    "    print((i,train_df[i].dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_df[['PassengerId','Age_x','Pclass','SibSp','Parch','Fare','Sex','Ticket','Embarked']]\n",
    "y=train_df[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Age_x', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Sex',\n",
       "       'Ticket', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[numeric_vars+categorical_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_vars=['PassengerId','Age_x','Pclass','SibSp','Parch','Fare']\n",
    "categorical_vars=['Sex','Ticket','Embarked']\n",
    "\n",
    "scale_step=('scaler',MinMaxScaler())\n",
    "num_pipe=Pipeline([scale_step])\n",
    "num_transformation=[('num_transformations',num_pipe,numeric_vars)]\n",
    "\n",
    "encoder_step=('encoder',OneHotEncoder())\n",
    "cat_pipe=Pipeline([encoder_step])\n",
    "cat_transformation=[('cat_transformations',cat_pipe,categorical_vars)]\n",
    "\n",
    "col_transformer=ColumnTransformer(transformers=num_transformation+cat_transformation)\n",
    "col_transformer.fit(X[numeric_vars+categorical_vars])\n",
    "X2=col_transformer.transform(X[numeric_vars+categorical_vars])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X2,y,test_size=0.2,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC=RandomForestClassifier(random_state=1234)\n",
    "params={\n",
    "    'n_estimators':range(50,200,50),\n",
    "    'max_depth': range(2,20),\n",
    "    'criterion':['gini','entropy']\n",
    "\n",
    "}\n",
    "RFC_mod=GridSearchCV(RFC,param_grid=params,cv=5,n_jobs=6)\n",
    "RFC_mod.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "pred_RFC_mod=RFC_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 18, 'n_estimators': 100}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_mod.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825844577957254"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_mod.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion: [[103   6]\n",
      " [ 24  46]]\n",
      "Accuracy : 0.8324022346368715\n",
      "Precision : 0.8846153846153846\n",
      "Recall : 0.6571428571428571\n",
      "AUC: 0.801048492791612\n",
      "GINI: 0.6020969855832241\n"
     ]
    }
   ],
   "source": [
    "print('Matriz de confusion:' , confusion_matrix(np.ravel(y_test),pred_RFC_mod))\n",
    "print('Accuracy :' , accuracy_score(np.ravel(y_test),pred_RFC_mod))\n",
    "print('Precision :' , precision_score(np.ravel(y_test),pred_RFC_mod))\n",
    "print('Recall :' , recall_score(np.ravel(y_test),pred_RFC_mod))\n",
    "print('AUC:' , roc_auc_score(np.ravel(y_test),pred_RFC_mod))\n",
    "print('GINI:' , (2*roc_auc_score(np.ravel(y_test),pred_RFC_mod))-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_criterion', 'param_max_depth', 'param_n_estimators', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_mod.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=18, n_estimators=50,\n",
       "                       random_state=1234)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RCF_adjusted=RandomForestClassifier(n_estimators=50,criterion='entropy',max_depth=18,random_state=1234)\n",
    "RCF_adjusted.fit(X_train,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=RCF_adjusted.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.72886345e-02, 6.56354886e-02, 6.07019773e-02, 2.83410866e-02,\n",
       "       2.86657099e-02, 1.09405142e-01, 1.29200603e-01, 1.36510941e-01,\n",
       "       1.94278546e-03, 7.32272984e-04, 2.49882137e-04, 1.13048034e-03,\n",
       "       8.01249890e-05, 2.04236131e-04, 3.48718082e-04, 3.90909792e-04,\n",
       "       1.18001446e-03, 2.78062342e-03, 1.12473500e-03, 1.41439572e-03,\n",
       "       2.36927268e-04, 3.80712466e-04, 1.70585484e-04, 3.83313027e-04,\n",
       "       7.07747547e-05, 1.72614211e-03, 7.53333872e-04, 4.56925638e-05,\n",
       "       0.00000000e+00, 1.61813174e-04, 1.20949071e-04, 7.75109746e-04,\n",
       "       8.63710081e-05, 0.00000000e+00, 0.00000000e+00, 1.35620186e-04,\n",
       "       0.00000000e+00, 7.21211028e-04, 1.76708366e-04, 2.00767133e-04,\n",
       "       3.90410895e-05, 5.24905104e-03, 2.59301988e-04, 4.01881629e-04,\n",
       "       6.83048721e-04, 6.75765598e-03, 0.00000000e+00, 2.44311398e-04,\n",
       "       1.60423777e-03, 0.00000000e+00, 6.50910245e-04, 1.29786937e-04,\n",
       "       4.92352454e-04, 1.28603612e-03, 2.15452459e-04, 3.39297510e-04,\n",
       "       2.08994610e-04, 3.89953548e-04, 0.00000000e+00, 4.52957370e-04,\n",
       "       2.35467495e-04, 1.14358166e-03, 0.00000000e+00, 3.82218321e-04,\n",
       "       1.17872032e-03, 0.00000000e+00, 1.23381393e-03, 6.93351951e-04,\n",
       "       3.30430889e-04, 4.49295812e-04, 5.82299921e-04, 5.17416615e-05,\n",
       "       1.17814308e-03, 1.32287714e-04, 6.58348707e-05, 8.52503012e-04,\n",
       "       0.00000000e+00, 6.94362861e-04, 0.00000000e+00, 1.94657992e-03,\n",
       "       6.65466141e-04, 1.76657059e-04, 9.47459655e-04, 7.29935625e-04,\n",
       "       1.10202658e-03, 4.79091829e-04, 7.42818876e-04, 5.92508619e-05,\n",
       "       7.97446370e-03, 4.72546783e-04, 1.61768902e-03, 1.48768011e-03,\n",
       "       2.49826220e-04, 7.56064650e-04, 4.55793158e-04, 6.51110783e-04,\n",
       "       4.10716788e-04, 2.90621072e-03, 4.92289999e-04, 0.00000000e+00,\n",
       "       2.08846919e-04, 1.89961010e-03, 1.39188269e-03, 1.22264141e-03,\n",
       "       1.03616372e-03, 2.51025214e-04, 0.00000000e+00, 1.63075829e-03,\n",
       "       4.72906248e-04, 0.00000000e+00, 0.00000000e+00, 3.97505703e-05,\n",
       "       1.10259671e-04, 0.00000000e+00, 1.15321710e-04, 0.00000000e+00,\n",
       "       7.96731203e-05, 1.24828175e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.42877943e-05, 2.50151116e-03, 1.76638207e-03, 2.18547786e-03,\n",
       "       0.00000000e+00, 2.75973954e-04, 3.16125269e-05, 0.00000000e+00,\n",
       "       1.82850500e-04, 0.00000000e+00, 3.94184281e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.20725377e-04,\n",
       "       1.21832160e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.51663865e-04, 1.55705222e-03, 0.00000000e+00,\n",
       "       4.87672965e-05, 0.00000000e+00, 2.85971300e-04, 6.59086563e-04,\n",
       "       4.14931844e-04, 3.23656984e-03, 6.33618150e-04, 0.00000000e+00,\n",
       "       8.11631639e-04, 2.09251812e-03, 1.36339664e-04, 0.00000000e+00,\n",
       "       2.08381681e-04, 6.51058407e-05, 6.30728195e-04, 1.88395108e-03,\n",
       "       0.00000000e+00, 5.50813458e-04, 1.25813591e-04, 1.97602133e-03,\n",
       "       4.21861460e-05, 2.07393277e-04, 5.73023877e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.56269292e-05, 9.89209681e-04, 3.35931234e-04,\n",
       "       0.00000000e+00, 2.81353707e-04, 2.66166138e-03, 1.54217861e-03,\n",
       "       3.44273107e-04, 1.02791102e-04, 2.45149751e-04, 3.17999643e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.14794826e-04, 0.00000000e+00,\n",
       "       6.70077726e-04, 2.17879795e-04, 2.18399147e-05, 4.24086146e-04,\n",
       "       2.15514492e-03, 1.73953437e-04, 8.56787146e-05, 0.00000000e+00,\n",
       "       3.60412921e-04, 0.00000000e+00, 2.27918835e-03, 2.56288499e-03,\n",
       "       3.94553244e-04, 1.52203079e-03, 2.84346542e-05, 1.06186799e-03,\n",
       "       2.43508200e-04, 7.22196222e-04, 4.20774681e-03, 1.37453757e-03,\n",
       "       4.56792920e-04, 0.00000000e+00, 9.30735656e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.93174261e-03, 2.25405134e-03,\n",
       "       4.49224982e-04, 2.61352640e-04, 1.08772872e-04, 1.81332424e-04,\n",
       "       7.20724091e-04, 2.47801416e-03, 3.12801796e-04, 3.09533942e-03,\n",
       "       3.02451322e-04, 2.78161962e-04, 4.23193837e-04, 1.85392787e-04,\n",
       "       7.57699321e-04, 1.30389381e-04, 1.65357342e-03, 8.72354489e-04,\n",
       "       8.78453686e-04, 3.28158555e-04, 8.98876775e-05, 5.91515784e-05,\n",
       "       3.83016928e-06, 0.00000000e+00, 1.11492457e-04, 5.32524630e-05,\n",
       "       8.43971049e-06, 7.19995727e-04, 0.00000000e+00, 2.02105035e-05,\n",
       "       2.60367571e-04, 8.26805873e-04, 1.88737753e-04, 5.79524860e-04,\n",
       "       4.37371442e-04, 1.42197805e-03, 1.59202500e-05, 5.26574180e-04,\n",
       "       5.29892061e-04, 6.56034375e-06, 5.47500740e-06, 8.90697395e-04,\n",
       "       6.21539635e-05, 0.00000000e+00, 6.18875746e-05, 1.15177709e-04,\n",
       "       1.12894497e-03, 3.49547331e-03, 5.27239597e-05, 0.00000000e+00,\n",
       "       2.41788834e-04, 1.17726538e-05, 1.56701798e-03, 1.95266951e-05,\n",
       "       1.75219566e-05, 5.92368422e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.41802455e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       9.19566407e-05, 0.00000000e+00, 8.22901013e-05, 6.08671733e-04,\n",
       "       3.49123219e-05, 1.89726452e-03, 3.54919981e-05, 8.00008702e-04,\n",
       "       0.00000000e+00, 2.11872628e-04, 0.00000000e+00, 2.14999874e-05,\n",
       "       1.05742824e-03, 0.00000000e+00, 1.10274681e-03, 7.14214031e-04,\n",
       "       1.90515501e-04, 6.27263750e-04, 3.33224261e-04, 1.19820206e-03,\n",
       "       0.00000000e+00, 9.24647723e-04, 0.00000000e+00, 7.89839747e-05,\n",
       "       1.31982472e-03, 0.00000000e+00, 1.05107825e-04, 1.33443092e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.72943683e-04,\n",
       "       1.09740095e-03, 0.00000000e+00, 0.00000000e+00, 4.10594225e-06,\n",
       "       4.84621049e-04, 7.59245270e-04, 2.98970422e-04, 4.95283850e-06,\n",
       "       1.27588353e-04, 8.36694764e-05, 1.53466698e-04, 1.95835278e-03,\n",
       "       2.28572592e-03, 1.89637568e-05, 1.45097626e-04, 1.82383928e-04,\n",
       "       0.00000000e+00, 3.22198847e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.87154833e-03, 0.00000000e+00, 0.00000000e+00, 1.73026406e-05,\n",
       "       5.58445463e-05, 1.93588607e-05, 0.00000000e+00, 1.93276259e-05,\n",
       "       6.91407503e-05, 4.33288634e-04, 0.00000000e+00, 1.28958293e-04,\n",
       "       4.40793226e-05, 2.99327222e-03, 0.00000000e+00, 3.16800558e-04,\n",
       "       7.87703083e-04, 8.12206576e-03, 0.00000000e+00, 1.85057870e-03,\n",
       "       7.19388547e-04, 4.43786901e-03, 2.23079851e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.06567413e-04, 3.67871826e-05, 8.89648426e-04,\n",
       "       3.36351749e-03, 3.24684170e-05, 0.00000000e+00, 1.53526009e-04,\n",
       "       3.80822791e-05, 1.36905959e-05, 0.00000000e+00, 4.76712146e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.49804387e-05, 2.31805255e-05,\n",
       "       7.85579157e-05, 4.29677328e-05, 5.80053274e-05, 4.22501484e-04,\n",
       "       4.98114881e-05, 4.28602884e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.57316316e-04, 4.78485935e-06, 0.00000000e+00,\n",
       "       2.38624300e-04, 2.81326158e-05, 0.00000000e+00, 3.03734550e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.08909879e-05, 0.00000000e+00,\n",
       "       3.07758944e-04, 8.76264400e-04, 0.00000000e+00, 2.35217307e-03,\n",
       "       3.13836570e-04, 0.00000000e+00, 2.37600714e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.27865392e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.86175040e-06, 1.27606984e-04,\n",
       "       0.00000000e+00, 7.33628421e-04, 0.00000000e+00, 1.49878304e-03,\n",
       "       5.59024745e-05, 9.83945525e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       6.66532437e-06, 1.17263006e-03, 1.38413946e-05, 8.86340430e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.47417430e-04, 0.00000000e+00,\n",
       "       2.13819022e-05, 0.00000000e+00, 1.67918900e-04, 1.05166299e-05,\n",
       "       0.00000000e+00, 4.73053671e-04, 3.95347369e-04, 2.90050602e-03,\n",
       "       2.06495227e-03, 5.75134140e-04, 0.00000000e+00, 1.36356006e-04,\n",
       "       1.11644002e-04, 1.10325570e-04, 5.93407032e-05, 1.10017712e-03,\n",
       "       1.62923120e-05, 0.00000000e+00, 1.37005128e-05, 6.46977893e-05,\n",
       "       0.00000000e+00, 2.75540224e-05, 0.00000000e+00, 1.00072080e-04,\n",
       "       6.20333511e-04, 0.00000000e+00, 1.06303983e-03, 7.19227842e-04,\n",
       "       4.78953930e-04, 0.00000000e+00, 0.00000000e+00, 8.61350227e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.35699002e-03, 0.00000000e+00,\n",
       "       9.23136522e-04, 6.41699702e-04, 1.97260624e-05, 7.27326160e-05,\n",
       "       0.00000000e+00, 3.09006049e-04, 0.00000000e+00, 1.25641570e-03,\n",
       "       3.34781284e-04, 8.81921842e-04, 6.17217239e-04, 7.94682674e-05,\n",
       "       2.02662801e-04, 7.02628589e-04, 1.55149583e-03, 2.77286515e-04,\n",
       "       1.33655365e-05, 9.95486275e-04, 9.09625819e-05, 0.00000000e+00,\n",
       "       1.43855081e-04, 1.04571340e-03, 1.39476340e-04, 1.35283674e-04,\n",
       "       2.98132585e-05, 7.21072906e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.61952932e-04, 0.00000000e+00, 0.00000000e+00, 1.69626770e-05,\n",
       "       7.84227331e-04, 0.00000000e+00, 1.16489616e-03, 2.09413336e-03,\n",
       "       2.84432993e-03, 9.37253789e-06, 1.55769365e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.98342850e-06, 1.44875703e-03, 0.00000000e+00,\n",
       "       1.93193548e-03, 0.00000000e+00, 1.30994867e-03, 5.98448897e-04,\n",
       "       7.02511782e-04, 6.05103796e-04, 2.29120124e-05, 3.47088731e-05,\n",
       "       7.15397622e-05, 6.22453195e-05, 1.65664338e-05, 2.27216981e-03,\n",
       "       2.44045537e-05, 3.17990768e-04, 4.99948845e-05, 6.70863842e-05,\n",
       "       1.79342888e-04, 9.18829174e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       6.96771865e-04, 5.19294892e-04, 1.86281388e-03, 7.56401365e-05,\n",
       "       1.88877275e-05, 3.12474189e-04, 9.88782992e-05, 0.00000000e+00,\n",
       "       5.18481693e-05, 2.07186353e-04, 7.44791322e-06, 3.13397674e-04,\n",
       "       5.51112696e-05, 0.00000000e+00, 0.00000000e+00, 2.03862777e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.08743118e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 5.09313766e-05, 1.86973433e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.93763648e-04, 2.12164019e-04, 3.18075445e-04,\n",
       "       1.06058846e-03, 1.46528296e-03, 3.47054555e-05, 9.18076568e-05,\n",
       "       0.00000000e+00, 8.54663089e-04, 6.25386515e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.89043897e-04, 3.31418350e-04,\n",
       "       1.60911345e-03, 1.58851838e-04, 8.76184476e-05, 9.78570738e-04,\n",
       "       2.98114817e-04, 3.05036694e-04, 0.00000000e+00, 6.96744693e-04,\n",
       "       8.57230770e-04, 1.42121029e-04, 9.36258565e-04, 3.14089099e-04,\n",
       "       2.95524980e-04, 2.76960838e-04, 1.63081643e-04, 0.00000000e+00,\n",
       "       2.60327260e-05, 0.00000000e+00, 1.60528514e-03, 4.82130190e-04,\n",
       "       2.23754602e-03, 3.45478211e-04, 5.34997230e-04, 1.09362072e-03,\n",
       "       4.55755535e-04, 1.77753566e-06, 2.35346610e-04, 4.78193658e-04,\n",
       "       4.48070125e-04, 0.00000000e+00, 9.90318897e-04, 2.03783182e-03,\n",
       "       1.83312208e-03, 3.06497579e-04, 2.05640420e-04, 3.04201502e-04,\n",
       "       9.12802319e-04, 1.52995540e-03, 8.78037678e-04, 2.99044433e-03,\n",
       "       1.52461720e-04, 5.13502067e-05, 4.47466846e-04, 6.54379413e-04,\n",
       "       5.32145797e-04, 2.17431845e-03, 9.65824161e-04, 0.00000000e+00,\n",
       "       5.69101562e-05, 5.59109964e-04, 5.74603361e-04, 2.92857927e-04,\n",
       "       1.64452141e-04, 1.84806956e-04, 5.72126020e-04, 4.54469779e-04,\n",
       "       8.62391622e-04, 1.71837851e-03, 1.16428407e-04, 2.44741754e-04,\n",
       "       1.53100137e-03, 9.26664712e-05, 8.72276004e-04, 5.88908104e-04,\n",
       "       1.18108975e-03, 9.63893477e-04, 1.18068661e-03, 3.13050649e-05,\n",
       "       8.06317848e-04, 1.20476295e-04, 6.42860470e-04, 1.64117625e-03,\n",
       "       5.25949026e-05, 2.09504947e-03, 6.95651352e-05, 8.35507526e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.00848242e-05, 5.11057032e-04,\n",
       "       0.00000000e+00, 5.22176352e-04, 4.66365199e-04, 1.57711462e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 7.79978596e-04, 3.25929744e-04,\n",
       "       2.89262466e-04, 4.95517984e-04, 4.50446891e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 4.21985525e-06, 0.00000000e+00, 1.92487414e-05,\n",
       "       6.15530782e-04, 7.03143204e-04, 2.99385293e-05, 5.55837632e-05,\n",
       "       0.00000000e+00, 4.09858464e-05, 3.89228770e-05, 1.80478005e-05,\n",
       "       5.02895216e-05, 9.51328455e-04, 3.87632408e-05, 1.52078800e-03,\n",
       "       2.66632831e-05, 1.69538550e-05, 2.54765815e-05, 4.65468924e-06,\n",
       "       2.90228361e-03, 0.00000000e+00, 2.79022377e-03, 5.84782445e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.07603359e-03,\n",
       "       2.03689125e-04, 9.42173050e-04, 0.00000000e+00, 2.77046277e-04,\n",
       "       0.00000000e+00, 3.66628815e-04, 5.42053839e-05, 0.00000000e+00,\n",
       "       3.86879029e-03, 7.44011647e-04, 2.50438071e-04, 0.00000000e+00,\n",
       "       6.13985729e-04, 1.31226290e-02, 5.75405534e-03, 1.18797981e-02,\n",
       "       2.21893730e-04])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693\n"
     ]
    }
   ],
   "source": [
    "print(len(RCF_adjusted.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_tot=pd.DataFrame([i for i in enumerate(importance)])\n",
    "feature_importance_tot.columns=['pos','importance']\n",
    "feature_importance_tot.sort_values(by='importance',ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.136511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.129201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.109405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.065635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.060702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.057289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.028666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.028341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689</td>\n",
       "      <td>0.013123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>691</td>\n",
       "      <td>0.011880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>341</td>\n",
       "      <td>0.008122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pos  importance\n",
       "7      7    0.136511\n",
       "6      6    0.129201\n",
       "5      5    0.109405\n",
       "1      1    0.065635\n",
       "2      2    0.060702\n",
       "0      0    0.057289\n",
       "4      4    0.028666\n",
       "3      3    0.028341\n",
       "689  689    0.013123\n",
       "691  691    0.011880\n",
       "341  341    0.008122"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_tot[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(height=feature_importance_tot.iloc[0:11]['importance'],x=range(0,11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC=GradientBoostingClassifier(random_state=1234)\n",
    "params={\n",
    "    'n_estimators':range(50,200,50),\n",
    "    'max_depth': range(2,20),\n",
    "    'learning_rate':np.arange(0.01,0.06,0.01)\n",
    "\n",
    "}\n",
    "GBC_mod=RandomizedSearchCV(GBC,params,cv=5,n_jobs=6)\n",
    "GBC_mod.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "pred_GBC_mod=GBC_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion: [[99 10]\n",
      " [20 50]]\n",
      "Accuracy : 0.8324022346368715\n",
      "Precision : 0.8333333333333334\n",
      "Recall : 0.7142857142857143\n",
      "AUC: 0.8112712975098297\n",
      "GINI: 0.6225425950196595\n"
     ]
    }
   ],
   "source": [
    "print('Matriz de confusion:' , confusion_matrix(np.ravel(y_test),pred_GBC_mod))\n",
    "print('Accuracy :' , accuracy_score(np.ravel(y_test),pred_GBC_mod))\n",
    "print('Precision :' , precision_score(np.ravel(y_test),pred_GBC_mod))\n",
    "print('Recall :' , recall_score(np.ravel(y_test),pred_GBC_mod))\n",
    "print('AUC:' , roc_auc_score(np.ravel(y_test),pred_GBC_mod))\n",
    "print('GINI:' , (2*roc_auc_score(np.ravel(y_test),pred_GBC_mod))-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 693)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 11:10:05.784782: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 11:10:06.576629: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo_IA(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,num_classes,hp_units0_0,hp_units0,hp_units1,hp_units2,hp_units3,hp_drop0_0,hp_drop0,hp_drop1,hp_drop2,hp_drop3,**kwargs):\n",
    "        super().__init__(**kwargs)  \n",
    "        self.num_classes=num_classes\n",
    "        self.hp_units0_0=hp_units0_0\n",
    "        self.hp_units0=hp_units0\n",
    "        self.hp_units1=hp_units1\n",
    "        self.hp_units2=hp_units2\n",
    "        self.hp_units3=hp_units3\n",
    "        self.hp_drop0_0=hp_drop0_0\n",
    "        self.hp_drop0=hp_drop0\n",
    "        self.hp_drop1=hp_drop1\n",
    "        self.hp_drop2=hp_drop2\n",
    "        self.hp_drop3=hp_drop3\n",
    "\n",
    "        # self.inputs= tf.keras.Input(shape=(712,10))\n",
    "        self.dense0_0= tf.keras.layers.Dense(units=self.hp_units0_0,activation='selu') \n",
    "        self.dropout0_0 = tf.keras.layers.Dropout(self.hp_drop0_0)\n",
    "        self.dense0= tf.keras.layers.Dense(units=self.hp_units0,activation='selu') \n",
    "        self.dropout0 = tf.keras.layers.Dropout(self.hp_drop0)\n",
    "        self.dense1= tf.keras.layers.Dense(units=self.hp_units1,activation='selu') \n",
    "        self.dropout1 = tf.keras.layers.Dropout(self.hp_drop1)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=self.hp_units2,activation='selu') \n",
    "        self.dropout2 = tf.keras.layers.Dropout(self.hp_drop2)\n",
    "        self.dense3 = tf.keras.layers.Dense(units=self.hp_units3,activation='selu') \n",
    "        self.dropout3 = tf.keras.layers.Dropout(self.hp_drop3)\n",
    "        self.batchn = tf.keras.layers.BatchNormalization()\n",
    "        self.dense4 = tf.keras.layers.Dense(units=self.num_classes,activation='sigmoid') \n",
    "\n",
    "    def call(self,input):\n",
    "       print(input.shape)\n",
    "       x = self.dense0_0 (input)\n",
    "       x = self.dropout0_0 (x)\n",
    "      #  x = self.batchn(x)\n",
    "    #    x = self.inputs(input)\n",
    "       x = self.dense0 (x)\n",
    "       x = self.dropout0 (x)\n",
    "       \n",
    "       x = self.dense1 (x)\n",
    "       x = self.dropout1 (x)\n",
    "       \n",
    "       x = self.dense2 (x)\n",
    "       x = self.dropout2 (x)\n",
    "       \n",
    "       x = self.dense3 (x)\n",
    "       x = self.dropout3 (x)\n",
    "       x = self.batchn(x)\n",
    "       output = self.dense4(x)\n",
    "\n",
    "       return output\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 693)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.1404494382022472\n",
      "  (0, 1)\t0.16049382716049382\n",
      "  (0, 2)\t1.0\n",
      "  (0, 3)\t0.125\n",
      "  (0, 5)\t0.021942337075458514\n",
      "  (0, 7)\t1.0\n",
      "  (0, 194)\t1.0\n",
      "  (0, 689)\t1.0\n"
     ]
    }
   ],
   "source": [
    "for i in X_train[0]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.3426966292134832\n",
      "  (0, 1)\t0.023703703703703703\n",
      "  (0, 3)\t0.125\n",
      "  (0, 4)\t0.3333333333333333\n",
      "  (0, 5)\t0.29580589980036276\n",
      "  (0, 7)\t1.0\n",
      "  (0, 45)\t1.0\n",
      "  (0, 691)\t1.0\n"
     ]
    }
   ],
   "source": [
    "for i in X_train[1]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.7089887640449438\n",
      "  (0, 1)\t0.6419753086419753\n",
      "  (0, 2)\t1.0\n",
      "  (0, 5)\t0.013768881414528002\n",
      "  (0, 7)\t1.0\n",
      "  (0, 353)\t1.0\n",
      "  (0, 691)\t1.0\n"
     ]
    }
   ],
   "source": [
    "for i in X_train[2]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.7224719101123596\n",
      "  (0, 1)\t0.36526063100137174\n",
      "  (0, 2)\t1.0\n",
      "  (0, 5)\t0.11027245763075773\n",
      "  (0, 7)\t1.0\n",
      "  (0, 88)\t1.0\n",
      "  (0, 691)\t1.0\n"
     ]
    }
   ],
   "source": [
    "for i in X_train[3]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X['Age_x']=X['Age_x'].apply(lambda x : np.round(x,decimals=0))\n",
    "# X['Fare']=X['Fare'].apply(lambda x : np.round(x,decimals=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId', 'Age_x', 'Pclass', 'SibSp', 'Parch', 'Fare']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age_x</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>13.3125</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId    Age_x  Pclass  SibSp  Parch     Fare\n",
       "0              1  22.0000       3      1      0   7.2500\n",
       "1              2  38.0000       1      1      0  71.2833\n",
       "2              3  26.0000       3      0      0   7.9250\n",
       "3              4  35.0000       1      1      0  53.1000\n",
       "4              5  35.0000       3      0      0   8.0500\n",
       "..           ...      ...     ...    ...    ...      ...\n",
       "886          887  27.0000       2      0      0  13.0000\n",
       "887          888  19.0000       1      0      0  30.0000\n",
       "888          889  13.3125       3      1      2  23.4500\n",
       "889          890  26.0000       1      0      0  30.0000\n",
       "890          891  32.0000       3      0      0   7.7500\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[numeric_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(max(X['Pclass']))\n",
    "print(min(X['Pclass']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.5\n",
       "1      0.5\n",
       "2      1.5\n",
       "3      0.5\n",
       "4      1.5\n",
       "      ... \n",
       "886    1.0\n",
       "887    0.5\n",
       "888    1.5\n",
       "889    0.5\n",
       "890    1.5\n",
       "Name: Pclass, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Pclass']/(max(X['Pclass'])-min(X['Pclass']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_encoder_local(array):\n",
    "    return (array/(np.max(array)-np.min(array)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46943/95992197.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i]=np.asarray(X[i]).astype(np.float32)\n",
      "/tmp/ipykernel_46943/95992197.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i]=min_max_encoder_local(X[i])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in X.columns:\n",
    "    if i in numeric_vars:\n",
    "        X[i]=np.asarray(X[i]).astype(np.float32)\n",
    "        X[i]=min_max_encoder_local(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_hot_local(array):\n",
    "    array_copy=array.copy()\n",
    "    array_copy[array_copy.isnull()==True]='NAN'\n",
    "    uni_values=np.sort(np.append(array_copy.unique(),'other'))\n",
    "    for val in enumerate(uni_values):\n",
    "        array_copy[array_copy==val[1]]=val[0]\n",
    "\n",
    "    return array_copy,uni_values\n",
    "\n",
    "# print(enumerate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        male\n",
       "1      female\n",
       "2      female\n",
       "3      female\n",
       "4        male\n",
       "        ...  \n",
       "886      male\n",
       "887    female\n",
       "888    female\n",
       "889      male\n",
       "890      male\n",
       "Name: Sex, Length: 891, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      1\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      1\n",
       "       ..\n",
       " 886    1\n",
       " 887    0\n",
       " 888    0\n",
       " 889    1\n",
       " 890    1\n",
       " Name: Sex, Length: 891, dtype: object,\n",
       " array(['female', 'male', 'other'], dtype=object))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_hot_local(X['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n",
      "Ticket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46943/738163752.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i],verbatims= One_hot_local(X[i])\n",
      "/tmp/ipykernel_46943/738163752.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i]=np.asarray(X[i]).astype(np.float32)\n",
      "/tmp/ipykernel_46943/738163752.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i],verbatims= One_hot_local(X[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46943/738163752.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i]=np.asarray(X[i]).astype(np.float32)\n",
      "/tmp/ipykernel_46943/738163752.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i],verbatims= One_hot_local(X[i])\n",
      "/tmp/ipykernel_46943/738163752.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[i]=np.asarray(X[i]).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "verbatim=[]\n",
    "for i in X.columns:\n",
    "    if i in categorical_vars:\n",
    "        print(i)\n",
    "        X[i],verbatims= One_hot_local(X[i])\n",
    "        X[i]=np.asarray(X[i]).astype(np.float32)\n",
    "        verbatim.append(verbatims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age_x</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.996629</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.997753</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.998876</td>\n",
       "      <td>0.164352</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.001124</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId     Age_x  Pclass  SibSp     Parch      Fare  Sex  Ticket  \\\n",
       "0       0.001124  0.271605     1.5  0.125  0.000000  0.014151  1.0   523.0   \n",
       "1       0.002247  0.469136     0.5  0.125  0.000000  0.139136  0.0   596.0   \n",
       "2       0.003371  0.320988     1.5  0.000  0.000000  0.015469  0.0   669.0   \n",
       "3       0.004494  0.432099     0.5  0.125  0.000000  0.103644  0.0    49.0   \n",
       "4       0.005618  0.432099     1.5  0.000  0.000000  0.015713  1.0   472.0   \n",
       "..           ...       ...     ...    ...       ...       ...  ...     ...   \n",
       "886     0.996629  0.333333     1.0  0.000  0.000000  0.025374  1.0   101.0   \n",
       "887     0.997753  0.234568     0.5  0.000  0.000000  0.058556  0.0    14.0   \n",
       "888     0.998876  0.164352     1.5  0.125  0.333333  0.045771  0.0   675.0   \n",
       "889     1.000000  0.320988     0.5  0.000  0.000000  0.058556  1.0     8.0   \n",
       "890     1.001124  0.395062     1.5  0.000  0.000000  0.015127  1.0   466.0   \n",
       "\n",
       "     Embarked  \n",
       "0         3.0  \n",
       "1         0.0  \n",
       "2         3.0  \n",
       "3         3.0  \n",
       "4         3.0  \n",
       "..        ...  \n",
       "886       3.0  \n",
       "887       3.0  \n",
       "888       3.0  \n",
       "889       0.0  \n",
       "890       2.0  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 11:10:08.107959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 11:10:08.133814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 11:10:08.134046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 11:10:08.134922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 11:10:08.135107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 11:10:08.135289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 11:10:08.631842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 11:10:08.632081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 11:10:08.632228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 11:10:08.632352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6613 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "X_train_ANN,X_test_ANN,y_train_ANN,y_test_ANN=train_test_split(X,y,test_size=0.2,random_state=1234)\n",
    "TF_dataset_train=tf.data.Dataset.from_tensor_slices((dict(X_train_ANN),np.ravel(y_train_ANN)))\n",
    "TF_dataset_test=tf.data.Dataset.from_tensor_slices((dict(X_test_ANN),np.ravel(y_test_ANN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 9)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ANN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "x_AI=TF_dataset_train.batch(X_train_ANN.shape[0]).shuffle(X_train_ANN.shape[0]).take(X_train_ANN.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 11:10:08.755904: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype float and shape [712]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "2023-08-22 11:10:08.756227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype float and shape [712]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    }
   ],
   "source": [
    "for i in x_AI:\n",
    "    x_AI_2=i[0]\n",
    "    y_AI_2=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_AI_test=TF_dataset_test.batch(X_test_ANN.shape[0]).take(X_test_ANN.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 11:10:08.778641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype float and shape [179]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "2023-08-22 11:10:08.778930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype int64 and shape [179]\n",
      "\t [[{{node Placeholder/_9}}]]\n"
     ]
    }
   ],
   "source": [
    "for i in x_AI_test:\n",
    "    x_AI_2_test=i[0]\n",
    "    y_AI_2_test=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PassengerId': <tf.Tensor: shape=(712,), dtype=float32, numpy=\n",
       " array([0.14157303, 0.3438202 , 0.71011233, 0.7235955 , 0.9089888 ,\n",
       "        0.30674157, 0.6269663 , 0.23146068, 0.7449438 , 0.5258427 ,\n",
       "        0.5292135 , 0.25617978, 0.0752809 , 0.7842697 , 0.01011236,\n",
       "        0.47191012, 0.9044944 , 0.47977528, 0.23258427, 0.7977528 ,\n",
       "        0.60674155, 0.5370787 , 0.05842697, 0.40786517, 0.56179774,\n",
       "        0.51910114, 0.2955056 , 0.21910113, 0.13370787, 0.19325842,\n",
       "        0.63820225, 0.0505618 , 0.6741573 , 0.43595505, 0.68876404,\n",
       "        0.21123596, 0.33483145, 0.952809  , 0.70561796, 0.5449438 ,\n",
       "        0.10898876, 0.79438204, 0.24606742, 0.5797753 , 0.19213483,\n",
       "        0.5494382 , 0.0483146 , 0.46179774, 0.16629213, 0.88988763,\n",
       "        0.9853933 , 0.4483146 , 0.4741573 , 0.16404495, 0.5674157 ,\n",
       "        0.21685393, 0.0764045 , 0.07977528, 0.17752808, 0.07078651,\n",
       "        0.3494382 , 0.13707866, 0.76516855, 0.07865169, 0.36741573,\n",
       "        0.31235954, 0.04157303, 0.4966292 , 0.78764045, 0.07303371,\n",
       "        0.22696629, 0.15505618, 0.38426965, 0.94269663, 0.45730338,\n",
       "        0.96629214, 0.9707865 , 0.31797752, 0.3247191 , 0.46404496,\n",
       "        0.43370786, 0.75617975, 0.7168539 , 0.85393256, 0.8191011 ,\n",
       "        0.8235955 , 0.752809  , 0.7382023 , 0.07191011, 0.03258427,\n",
       "        0.30449438, 0.83707863, 0.08314607, 0.4764045 , 0.10786517,\n",
       "        0.46741572, 0.17303371, 0.35505617, 0.7539326 , 0.2494382 ,\n",
       "        0.7595506 , 0.8764045 , 0.18876405, 0.547191  , 0.54044944,\n",
       "        0.9235955 , 0.7292135 , 0.894382  , 0.05955056, 0.41235954,\n",
       "        0.8988764 , 0.2988764 , 0.08764045, 0.9337079 , 0.2258427 ,\n",
       "        0.56067413, 0.95955056, 0.13033707, 0.72808987, 0.26179776,\n",
       "        0.3966292 , 0.03820225, 0.44269663, 0.96067417, 0.6022472 ,\n",
       "        0.5067416 , 0.44157302, 0.27865168, 0.5988764 , 0.21460675,\n",
       "        0.80786514, 0.7820225 , 0.994382  , 0.36067414, 0.41573033,\n",
       "        0.20449439, 0.852809  , 0.63707864, 0.46292135, 0.7786517 ,\n",
       "        0.31348315, 0.73370785, 0.3696629 , 0.6247191 , 0.80898875,\n",
       "        0.37078652, 0.7483146 , 0.2483146 , 0.2730337 , 0.40449437,\n",
       "        0.12808989, 0.40898877, 0.86292136, 0.6988764 , 0.38202247,\n",
       "        0.01573034, 0.06516854, 0.7831461 , 0.19550562, 0.8292135 ,\n",
       "        0.7966292 , 0.02022472, 0.91235954, 0.18988764, 0.5505618 ,\n",
       "        0.98089886, 0.9786517 , 0.4808989 , 0.8730337 , 0.46853933,\n",
       "        0.13932584, 0.02359551, 0.7       , 0.88426965, 0.10449439,\n",
       "        0.44494382, 0.8269663 , 0.66179776, 0.6011236 , 0.8494382 ,\n",
       "        0.8573034 , 0.6808989 , 0.8280899 , 0.33370787, 0.16853933,\n",
       "        0.3955056 , 0.98876405, 0.06741573, 0.94494385, 0.17078651,\n",
       "        0.44382024, 0.30898875, 0.81685394, 0.36853933, 0.20898877,\n",
       "        0.5966292 , 0.76292133, 0.347191  , 0.56516856, 0.03932584,\n",
       "        0.28651685, 0.10337079, 0.53483146, 0.9179775 , 0.12584269,\n",
       "        0.78089887, 0.9696629 , 0.45617977, 0.66853935, 0.20337078,\n",
       "        0.60898876, 0.41685393, 0.9247191 , 0.05730337, 0.3775281 ,\n",
       "        0.8775281 , 0.5022472 , 0.38089886, 0.08089887, 0.5910112 ,\n",
       "        0.53370786, 0.8247191 , 0.2539326 , 0.64044946, 0.66292137,\n",
       "        0.5       , 0.6044944 , 0.8       , 0.9101124 , 0.03146067,\n",
       "        0.8662921 , 0.51348317, 0.05617978, 0.68988764, 0.61685395,\n",
       "        0.93483144, 0.86853933, 0.26966292, 0.888764  , 0.44044945,\n",
       "        0.21348314, 0.30786517, 0.73595506, 0.69101125, 0.9831461 ,\n",
       "        0.05393258, 0.5808989 , 0.29662922, 0.8955056 , 0.38764045,\n",
       "        0.22808988, 0.552809  , 0.85955054, 0.96516854, 0.33707866,\n",
       "        0.86404496, 0.50898874, 0.3258427 , 0.7404494 , 0.90786517,\n",
       "        0.947191  , 0.28089887, 0.8820225 , 0.20786516, 0.24269663,\n",
       "        0.24494383, 0.71910113, 0.40561798, 0.39325842, 0.7764045 ,\n",
       "        0.7247191 , 0.9404494 , 0.3022472 , 0.8213483 , 0.91573036,\n",
       "        0.9977528 , 0.30337077, 0.28314605, 0.98651683, 0.0258427 ,\n",
       "        0.12247191, 0.6730337 , 0.505618  , 0.25842696, 0.12359551,\n",
       "        0.92134833, 0.26067415, 0.5078652 , 0.28539327, 0.14606741,\n",
       "        0.1719101 , 0.94382024, 0.7258427 , 0.36404493, 0.71348315,\n",
       "        0.5224719 , 0.29438204, 0.36179775, 0.34044945, 0.7078652 ,\n",
       "        0.5662921 , 0.89213485, 0.81011236, 0.39775282, 0.6123595 ,\n",
       "        0.3483146 , 0.00786517, 0.06404494, 0.08988764, 0.7741573 ,\n",
       "        0.06179775, 0.04269663, 0.7707865 , 0.46629214, 0.8224719 ,\n",
       "        0.6426966 , 0.6505618 , 0.6033708 , 0.6       , 0.7775281 ,\n",
       "        0.15617977, 0.11910112, 0.45842695, 0.8303371 , 0.08426967,\n",
       "        0.1       , 0.33820224, 0.7516854 , 0.6797753 , 0.7089888 ,\n",
       "        0.20561798, 0.92921346, 0.15955056, 0.19438203, 0.02921348,\n",
       "        0.26853934, 0.24044944, 0.54157305, 0.86067414, 0.83258426,\n",
       "        0.81123596, 0.66067415, 0.6775281 , 0.7213483 , 0.805618  ,\n",
       "        0.4494382 , 0.8202247 , 0.02247191, 0.25168538, 0.0011236 ,\n",
       "        0.605618  , 0.6955056 , 0.6876404 , 0.83146065, 0.7011236 ,\n",
       "        0.11011236, 0.6865169 , 0.06292135, 0.0494382 , 0.78876406,\n",
       "        0.9202247 , 0.15168539, 0.20224719, 0.8044944 , 0.5898876 ,\n",
       "        0.5146067 , 0.31573033, 0.9033708 , 0.2235955 , 0.91348314,\n",
       "        0.18314607, 0.51123595, 0.48426965, 0.04382022, 0.7022472 ,\n",
       "        0.18202247, 0.6550562 , 0.04044944, 0.00337079, 0.48651686,\n",
       "        0.10224719, 0.6337079 , 0.34269664, 0.28426966, 0.41011235,\n",
       "        0.11573034, 0.74269664, 0.11460674, 0.43707865, 0.09662921,\n",
       "        0.61348313, 0.15842697, 1.        , 0.6640449 , 0.5820225 ,\n",
       "        0.9842697 , 0.9640449 , 0.6179775 , 0.48988765, 0.76629215,\n",
       "        0.61011237, 0.9       , 0.5955056 , 0.8449438 , 0.1247191 ,\n",
       "        0.34494382, 0.9775281 , 0.46067417, 0.5269663 , 0.8516854 ,\n",
       "        0.81573033, 0.21573034, 0.7932584 , 0.09101123, 0.01910112,\n",
       "        0.2       , 0.6235955 , 0.43258426, 0.57078654, 0.5157303 ,\n",
       "        0.8348315 , 0.9460674 , 0.4775281 , 0.6348315 , 0.19662921,\n",
       "        0.7269663 , 0.16292135, 0.45280898, 0.43932584, 0.95168537,\n",
       "        0.1494382 , 0.5202247 , 0.8741573 , 0.252809  , 0.21011236,\n",
       "        0.9752809 , 0.02696629, 0.69775283, 0.8426966 , 0.5382022 ,\n",
       "        0.5314607 , 0.63595504, 0.4707865 , 0.55617976, 0.4292135 ,\n",
       "        0.5719101 , 0.03595506, 0.9561798 , 0.93707865, 0.58651686,\n",
       "        0.21797752, 0.22921348, 0.26741573, 0.12921348, 0.3752809 ,\n",
       "        0.8483146 , 0.8651685 , 0.5775281 , 0.7067416 , 0.7314607 ,\n",
       "        0.78651685, 0.2977528 , 0.4033708 , 0.8123596 , 0.3797753 ,\n",
       "        0.59213483, 0.75842696, 0.6573034 , 0.4280899 , 0.00674157,\n",
       "        0.9303371 , 0.647191  , 0.78539324, 0.86179775, 0.68202245,\n",
       "        0.6280899 , 0.84044945, 0.14382023, 0.9550562 , 0.29325843,\n",
       "        0.12022472, 0.48764044, 0.2011236 , 0.6438202 , 0.7303371 ,\n",
       "        0.41460675, 0.5685393 , 0.6696629 , 0.7617977 , 0.39438203,\n",
       "        0.3539326 , 0.88651687, 0.05505618, 0.3516854 , 0.03707865,\n",
       "        0.50337076, 0.23595506, 0.29213482, 0.35617977, 0.65280896,\n",
       "        0.31910113, 0.6494382 , 0.7224719 , 0.12134831, 0.8977528 ,\n",
       "        0.4550562 , 0.61573035, 0.74157304, 0.7910112 , 0.6224719 ,\n",
       "        0.8011236 , 0.6191011 , 0.0988764 , 0.7988764 , 0.18651685,\n",
       "        0.42696628, 0.23707865, 0.33258426, 0.6202247 , 0.9719101 ,\n",
       "        0.9269663 , 0.5977528 , 0.48314607, 0.9685393 , 0.9224719 ,\n",
       "        0.8258427 , 0.51797754, 0.01460674, 0.45955056, 0.54831463,\n",
       "        0.63932586, 0.11123595, 0.32247192, 0.7393258 , 0.5730337 ,\n",
       "        0.78988767, 0.28988764, 0.60786515, 0.35730338, 0.6707865 ,\n",
       "        0.18539326, 0.98988765, 0.38651684, 0.7505618 , 0.81797755,\n",
       "        0.35842696, 0.63146067, 0.35280898, 0.23820224, 0.7179775 ,\n",
       "        0.64494383, 0.8707865 , 0.01797753, 0.08539326, 0.55505615,\n",
       "        0.58539325, 0.23483147, 0.66741574, 0.13258427, 0.3741573 ,\n",
       "        0.3280899 , 0.23932584, 0.91460675, 0.5303371 , 0.57865167,\n",
       "        0.7674157 , 0.93932587, 0.75730336, 0.6752809 , 0.32921347,\n",
       "        0.49438202, 1.0011235 , 0.05280899, 0.9629213 , 0.6651685 ,\n",
       "        0.14719102, 0.941573  , 0.4505618 , 0.59325844, 0.95842695,\n",
       "        0.84719104, 0.7696629 , 0.15393259, 0.9258427 , 0.16966292,\n",
       "        0.07752809, 0.03033708, 0.80224717, 0.44606742, 0.16067415,\n",
       "        0.00224719, 0.47865167, 0.70449436, 0.99550563, 0.5280899 ,\n",
       "        0.50449437, 0.49101123, 0.28202248, 0.95730335, 0.13483146,\n",
       "        0.22134832, 0.5595506 , 0.4247191 , 0.46966293, 0.38988763,\n",
       "        0.89101124, 0.3988764 , 0.71235955, 0.28876406, 0.694382  ,\n",
       "        0.38314608, 0.20674157, 0.64606744, 0.9325843 , 0.48876405,\n",
       "        0.7460674 , 0.3764045 , 0.26516855, 0.3505618 , 0.38876405,\n",
       "        0.11685393, 0.09325843, 0.00561798, 0.32022473, 0.01235955,\n",
       "        0.61460674, 0.7730337 , 0.98202246, 0.2752809 , 0.6292135 ,\n",
       "        0.8438202 , 0.79550564, 0.152809  , 0.90674156, 0.41123596,\n",
       "        0.90561795, 0.54269665, 0.77191013, 0.6719101 , 0.02134831,\n",
       "        0.9921348 , 0.34157303, 0.09775281, 0.26629212, 0.49550563,\n",
       "        0.04719101, 0.59438205, 0.05168539, 0.09550562, 0.6764045 ,\n",
       "        0.8561798 , 0.7550562 , 0.7033708 , 0.22247191, 0.68426967,\n",
       "        0.13146068, 0.8786517 , 0.09213483, 0.9494382 , 0.5516854 ,\n",
       "        0.9314607 , 0.51235956, 0.27415732, 0.01685393, 0.5235955 ,\n",
       "        0.6966292 , 0.41797754, 0.5168539 , 0.31011236, 0.29101124,\n",
       "        0.00449438, 0.9764045 , 0.9483146 , 0.83820224, 0.72022474,\n",
       "        0.15730338, 0.8359551 , 0.22022472, 0.5696629 , 0.9022472 ,\n",
       "        0.33033708, 0.08651686, 0.858427  , 0.8460674 , 0.6325843 ,\n",
       "        0.48539326, 0.5741573 , 0.27752808, 0.43146068, 0.37865168,\n",
       "        0.36629215, 0.5359551 , 0.13595505, 0.49775282, 0.4213483 ,\n",
       "        0.89325845, 0.84157306, 0.17865169, 0.7685393 , 0.03483146,\n",
       "        0.1741573 , 0.26292136, 0.31460676, 0.7752809 , 0.73707867,\n",
       "        0.747191  , 0.41910112, 0.23033708, 0.06067416, 0.33146068,\n",
       "        0.8134831 , 0.9168539 ], dtype=float32)>,\n",
       " 'Age_x': <tf.Tensor: shape=(712,), dtype=float32, numpy=\n",
       " array([ 0.14814815,  0.01135802,  0.6296296 ,  0.35291496,  0.4814815 ,\n",
       "         0.50617284,  0.4923457 ,  0.02469136,  0.5802469 ,  0.69135803,\n",
       "         0.35291496,  0.25308642,  0.3580247 ,  0.24305555,  0.33333334,\n",
       "         0.12345679,  0.33333334,  0.34567901,  0.39506173,  0.16179012,\n",
       "         0.27160493,  0.3580247 ,  0.25925925,  0.5555556 ,  0.2962963 ,\n",
       "         0.41975307,  0.6419753 ,  0.54320985,  0.2962963 ,  0.04938272,\n",
       "         0.3580247 ,  0.2345679 ,  0.60493827,  0.44444445,  0.24305555,\n",
       "         0.5555556 ,  0.02469136,  0.43209878,  0.25925925,  0.30864197,\n",
       "         0.8765432 ,  0.5555556 ,  0.39506173,  0.5802469 ,  0.75308645,\n",
       "         0.37037036,  0.3368607 ,  0.35291496,  0.11111111,  0.19753087,\n",
       "         0.24691358,  0.28395063,  0.25925925,  0.2345679 ,  0.19753087,\n",
       "         0.2345679 ,  0.2345679 ,  0.39506173,  0.37037036,  0.5555556 ,\n",
       "         0.2962963 ,  0.35291496,  0.24305555,  0.32098764,  0.75308645,\n",
       "         0.41424757,  0.3368607 ,  0.24691358,  0.22222222,  0.4923457 ,\n",
       "         0.13437796,  0.45679012,  0.2962963 ,  0.39506173,  0.6296296 ,\n",
       "         0.3368607 ,  0.16435185,  0.19753087,  0.5185185 ,  0.4074074 ,\n",
       "         0.22222222,  0.86419755,  0.38271606,  0.4074074 ,  0.30864197,\n",
       "         0.41424757,  0.43160492,  0.35291496,  0.04938272,  0.24305555,\n",
       "         0.54000473,  0.38271606,  0.32098764,  0.34567901,  0.35291496,\n",
       "         0.32438272,  0.5       ,  0.32098764,  0.49382716,  0.33333334,\n",
       "         0.22222222,  0.5308642 ,  0.5555556 ,  0.43209878,  0.11111111,\n",
       "         0.33333334,  0.35291496,  0.4814815 ,  0.60493827,  0.7407407 ,\n",
       "         0.37037036,  0.44444445,  0.35291496,  0.18518518,  0.34567901,\n",
       "         0.30864197,  0.19753087,  0.25925925,  0.69135803,  0.72839504,\n",
       "         0.18518518,  0.8148148 ,  0.28395063,  0.54320985,  0.08641975,\n",
       "         0.44444445,  0.34567901,  0.2962963 ,  0.20987654,  0.39506173,\n",
       "         0.45679012,  0.6419753 ,  0.30864197,  0.27160493,  0.2962963 ,\n",
       "         0.37160495,  0.41975307,  0.2345679 ,  0.45679012,  0.35291496,\n",
       "         0.08641975,  0.25925925,  0.38271606,  0.7654321 ,  0.4074074 ,\n",
       "         0.19753087,  0.39506173,  0.19753087,  0.3580247 ,  0.24305555,\n",
       "         0.24691358,  0.43209878,  0.37654322,  0.5185185 ,  0.5555556 ,\n",
       "         0.4814815 ,  0.35185185,  0.54320985,  0.25925925,  0.43209878,\n",
       "         0.27160493,  0.41424757,  0.4814815 ,  0.54000473,  0.11111111,\n",
       "         0.4074074 ,  0.32098764,  0.2345679 ,  0.45679012,  0.41975307,\n",
       "         0.40123457,  0.43209878,  0.24691358,  0.22222222,  0.56790125,\n",
       "         0.27160493,  0.35185185,  0.27160493,  0.37037036,  0.0082716 ,\n",
       "         0.24691358,  0.44444445,  0.5925926 ,  0.29012346,  0.5185185 ,\n",
       "         0.54000473,  0.69135803,  0.13580246,  0.24691358,  0.27160493,\n",
       "         0.2962963 ,  0.24305555,  0.37037036,  0.44444445,  0.54000473,\n",
       "         0.02469136,  0.5308642 ,  0.37037036,  0.24305555,  0.34567901,\n",
       "         0.50617284,  0.24691358,  0.54000473,  0.28395063,  0.17901234,\n",
       "         0.7407407 ,  0.5925926 ,  0.41975307,  0.45679012,  0.16435185,\n",
       "         0.11111111,  0.30864197,  0.4691358 ,  0.08641975,  0.35291496,\n",
       "         0.16049382,  0.16049382,  0.5555556 ,  0.19753087,  0.5       ,\n",
       "         0.27160493,  0.28395063,  0.27160493,  0.39506173,  0.35291496,\n",
       "         0.35291496,  0.37037036,  0.54000473,  0.4074074 ,  0.2345679 ,\n",
       "         0.2962963 ,  0.80246913,  0.22222222,  0.45679012,  0.4074074 ,\n",
       "         0.01024691,  0.7037037 ,  0.4074074 ,  0.45679012,  0.25925925,\n",
       "         0.44444445,  0.45679012,  0.22222222,  0.43209878,  0.34567901,\n",
       "         0.24305555,  0.41975307,  0.49382716,  0.60493827,  0.44444445,\n",
       "         0.41975307,  0.25925925,  0.19753087,  0.2962963 ,  0.61728394,\n",
       "         0.45679012,  0.37037036,  0.27160493,  0.28395063,  0.22222222,\n",
       "         0.37037036,  0.6666667 ,  0.30864197,  0.04938272,  0.38271606,\n",
       "         0.5185185 ,  0.35291496,  0.49382716,  0.5185185 ,  0.38271606,\n",
       "         0.00925926,  0.25925925,  0.7160494 ,  0.3580247 ,  0.37654322,\n",
       "         0.2345679 ,  0.43209878,  0.3580247 ,  0.2345679 ,  0.18518518,\n",
       "         0.4691358 ,  0.3368607 ,  0.6419753 ,  0.20702752,  0.24305555,\n",
       "         0.12345679,  0.3580247 ,  0.35291496,  0.37037036,  0.5555556 ,\n",
       "         0.6851852 ,  0.4923457 ,  0.5925926 ,  0.27160493,  0.11111111,\n",
       "         0.35291496,  0.03703704,  0.33333334,  0.2345679 ,  0.45679012,\n",
       "         0.45679012,  0.4923457 ,  0.07407407,  0.30864197,  0.61728394,\n",
       "         0.37037036,  0.6666667 ,  0.25925925,  0.37037036,  0.22222222,\n",
       "         0.80246913,  0.25925925,  0.30864197,  0.54320985,  0.13580246,\n",
       "         0.654321  ,  0.18209876,  0.5555556 ,  0.18518518,  0.04938272,\n",
       "         0.19753087,  0.34567901,  0.03703704,  0.35291496,  0.39506173,\n",
       "         0.28395063,  0.24305555,  0.5308642 ,  0.43209878,  0.9876543 ,\n",
       "         0.11111111,  0.35291496,  0.27160493,  0.01234568,  0.4691358 ,\n",
       "         0.2345679 ,  0.37037036,  0.41424757,  0.6296296 ,  0.54000473,\n",
       "         0.20987654,  0.7407407 ,  0.54000473,  0.2962963 ,  0.4691358 ,\n",
       "         0.34567901,  0.30864197,  0.18209876,  0.35291496,  0.27160493,\n",
       "         0.35291496,  0.04938272,  0.35291496,  0.35291496,  0.25925925,\n",
       "         0.28395063,  0.4814815 ,  0.54000473,  0.03703704,  0.43209878,\n",
       "         0.5308642 ,  0.30864197,  0.44444445,  0.2345679 ,  0.3368607 ,\n",
       "         0.43160492,  0.80246913,  0.00518519,  0.24305555,  0.43209878,\n",
       "         0.32098764,  0.35291496,  0.34567901,  0.22222222,  0.25925925,\n",
       "         0.49382716,  0.6666667 ,  0.5185185 ,  0.32098764,  0.5185185 ,\n",
       "         0.3580247 ,  0.35291496,  0.35291496,  0.7654321 ,  0.45679012,\n",
       "         0.25925925,  0.61728394,  0.35291496,  0.45679012,  0.4074074 ,\n",
       "         0.79012346,  0.18518518,  0.32098764,  0.43209878,  0.45679012,\n",
       "         0.18518518,  0.6296296 ,  0.09876543,  0.17283951,  0.33333334,\n",
       "         0.13580246,  0.41975307,  0.28395063,  0.07407407,  0.5802469 ,\n",
       "         0.45194003,  0.04938272,  0.20702752,  0.45679012,  0.22222222,\n",
       "         0.24691358,  0.2345679 ,  0.4814815 ,  0.27160493,  0.02469136,\n",
       "         0.61728394,  0.27160493,  0.35291496,  0.54000473,  0.61728394,\n",
       "         0.25925925,  0.19753087,  0.22222222,  0.32438272,  0.69135803,\n",
       "         0.2345679 ,  0.22222222,  0.25925925,  0.44444445,  0.13437796,\n",
       "         0.5802469 ,  0.5802469 ,  0.0617284 ,  0.4691358 ,  0.24305555,\n",
       "         0.38271606,  0.34567901,  0.33333334,  0.38271606,  0.27160493,\n",
       "         0.4074074 ,  0.2962963 ,  0.37037036,  0.25925925,  0.01234568,\n",
       "         0.34567901,  0.45194003,  0.04938272,  0.28395063,  0.27160493,\n",
       "         0.03703704,  0.5617284 ,  0.09876543,  0.20987654,  0.19753087,\n",
       "         0.5925926 ,  0.39506173,  0.6666667 ,  0.32098764,  0.35291496,\n",
       "         0.5185185 ,  0.24305555,  0.24305555,  0.41975307,  0.50617284,\n",
       "         0.61728394,  0.41424757,  0.3368607 ,  0.5185185 ,  0.45679012,\n",
       "         0.01234568,  0.2345679 ,  0.60493827,  0.4923457 ,  0.37037036,\n",
       "         0.4814815 ,  0.37037036,  0.2962963 ,  0.45194003,  0.45679012,\n",
       "         0.25925925,  0.20987654,  0.37037036,  0.44444445,  0.28395063,\n",
       "         0.24305555,  0.22222222,  0.44444445,  0.22222222,  0.28395063,\n",
       "         0.5308642 ,  0.01234568,  0.3368607 ,  0.32098764,  0.24305555,\n",
       "         0.41975307,  0.49382716,  0.61728394,  0.2962963 ,  0.30864197,\n",
       "         0.2345679 ,  0.4814815 ,  0.02469136,  0.35291496,  0.37037036,\n",
       "         0.24691358,  0.37160495,  0.7160494 ,  0.30864197,  0.27160493,\n",
       "         0.5925926 ,  0.20987654,  0.35291496,  0.2962963 ,  0.11111111,\n",
       "         0.2345679 ,  0.2962963 ,  0.4923457 ,  0.33333334,  0.2962963 ,\n",
       "         0.02469136,  0.3368607 ,  0.39506173,  0.25925925,  0.6419753 ,\n",
       "         0.28395063,  0.5925926 ,  0.24691358,  0.25925925,  0.7160494 ,\n",
       "         0.3368607 ,  0.41975307,  0.37037036,  0.39506173,  0.32098764,\n",
       "         0.22222222,  0.37037036,  0.44444445,  0.6666667 ,  0.41358024,\n",
       "         0.01234568,  0.30864197,  0.30864197,  0.35291496,  0.24305555,\n",
       "         0.38271606,  0.49382716,  0.34567901,  0.43209878,  0.50617284,\n",
       "         0.24305555,  0.6666667 ,  0.67901236,  0.30864197,  0.8765432 ,\n",
       "         0.37037036,  0.19753087, -0.01234568,  0.3580247 ,  0.4691358 ,\n",
       "         0.2345679 ,  0.27160493,  0.07407407,  0.4691358 ,  0.2962963 ,\n",
       "         0.24691358,  0.4814815 ,  0.38271606,  0.2962963 ,  0.44444445,\n",
       "         0.38271606,  0.39506173,  0.45679012,  0.5555556 ,  0.6419753 ,\n",
       "         0.4074074 ,  0.35291496,  0.4814815 ,  0.54000473,  0.11111111,\n",
       "         0.28395063,  0.7407407 ,  0.2345679 ,  0.33333334,  0.6296296 ,\n",
       "         0.20987654,  0.3368607 ,  0.3580247 ,  0.38271606,  0.2962963 ,\n",
       "         0.4691358 ,  0.35291496,  0.7037037 ,  0.4814815 ,  0.00925926,\n",
       "         0.0617284 ,  0.25925925,  0.35291496,  0.91358024,  0.02469136,\n",
       "         0.45679012,  0.35291496,  0.33333334,  0.22222222,  0.49382716,\n",
       "         0.16435185,  0.3368607 ,  0.54000473,  0.45194003,  0.32098764,\n",
       "         0.02469136,  0.01234568,  0.19753087,  0.7654321 ,  0.61728394,\n",
       "         0.44444445,  0.43160492,  0.32438272,  0.22222222,  0.2962963 ,\n",
       "         0.4074074 ,  0.24305555,  0.43209878,  0.54000473,  0.04938272,\n",
       "         0.2345679 ,  0.2345679 ,  0.5802469 ,  0.37037036,  0.44444445,\n",
       "         0.04938272,  0.5185185 ,  0.28395063,  0.4814815 ,  0.37037036,\n",
       "         0.38271606,  0.61728394,  0.17283951,  0.60493827,  0.38271606,\n",
       "         0.27160493,  0.37037036,  0.19753087,  0.54320985,  0.5555556 ,\n",
       "         0.33333334,  0.4814815 ,  0.35291496,  0.20987654,  0.35291496,\n",
       "         0.50617284,  0.38271606,  0.75308645,  0.5185185 ,  0.27160493,\n",
       "         0.8703704 ,  0.20987654,  0.3580247 ,  0.20987654,  0.35291496,\n",
       "         0.45679012,  0.3580247 ,  0.27160493,  0.17283951,  0.4691358 ,\n",
       "         0.32098764,  0.22222222,  0.45679012,  0.7777778 ,  0.43209878,\n",
       "         0.43209878,  0.35291496,  0.42592594,  0.86419755,  0.24691358,\n",
       "         0.2962963 ,  0.2962963 ,  0.7160494 ,  0.4074074 ,  0.13580246,\n",
       "         0.2962963 ,  0.35291496,  0.44444445,  0.4074074 ,  0.34567901,\n",
       "         0.32438272,  0.3580247 ,  0.30864197,  0.43209878,  0.3580247 ,\n",
       "         0.44444445,  0.41975307,  0.25925925,  0.30864197,  0.03703704,\n",
       "         0.30864197,  0.2345679 ,  0.35291496,  0.17283951,  0.49382716,\n",
       "         0.35291496,  0.0617284 ,  0.43209878,  0.18518518,  0.2962963 ,\n",
       "         0.24691358,  0.2345679 ,  0.22222222,  0.3580247 ,  0.2962963 ,\n",
       "         0.61728394,  0.54000473], dtype=float32)>,\n",
       " 'Pclass': <tf.Tensor: shape=(712,), dtype=float32, numpy=\n",
       " array([1.5, 0.5, 1.5, 1.5, 1. , 1. , 0.5, 1.5, 0.5, 0.5, 1.5, 1.5, 1. ,\n",
       "        1.5, 1.5, 1.5, 1.5, 1. , 1.5, 1.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "        0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 0.5, 1. , 1.5, 0.5, 0.5, 1.5, 0.5,\n",
       "        0.5, 0.5, 1. , 0.5, 0.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1. , 1.5, 1. ,\n",
       "        1.5, 1. , 0.5, 1.5, 1.5, 1. , 1.5, 0.5, 0.5, 1.5, 1.5, 1.5, 1.5,\n",
       "        1. , 1.5, 1.5, 0.5, 0.5, 1.5, 0.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "        1. , 0.5, 1. , 1. , 1. , 0.5, 1. , 1. , 0.5, 1.5, 1.5, 1.5, 0.5,\n",
       "        1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1. , 1. , 1.5, 0.5, 1.5, 0.5,\n",
       "        1.5, 1.5, 1.5, 1. , 0.5, 0.5, 1.5, 1. , 1.5, 1.5, 1.5, 0.5, 0.5,\n",
       "        1.5, 0.5, 1. , 1.5, 1. , 0.5, 1. , 1. , 1. , 1.5, 1. , 1.5, 1. ,\n",
       "        1.5, 1. , 1.5, 1.5, 0.5, 1. , 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "        0.5, 1.5, 0.5, 1. , 1.5, 1. , 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 1.5,\n",
       "        1.5, 1.5, 1.5, 0.5, 0.5, 1. , 1.5, 0.5, 1.5, 0.5, 1.5, 1. , 1.5,\n",
       "        1. , 1. , 1. , 1.5, 1.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1. , 1.5, 1.5,\n",
       "        1.5, 1.5, 1. , 0.5, 0.5, 1.5, 1.5, 0.5, 1.5, 1.5, 1. , 1. , 0.5,\n",
       "        1. , 1.5, 1. , 1.5, 0.5, 1.5, 1.5, 0.5, 1.5, 1.5, 0.5, 0.5, 1. ,\n",
       "        1. , 1.5, 1.5, 0.5, 0.5, 1.5, 1.5, 1.5, 1. , 1.5, 1.5, 1.5, 1.5,\n",
       "        1. , 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 0.5, 0.5, 1.5, 0.5, 1.5, 1.5,\n",
       "        1.5, 1. , 1. , 1. , 1.5, 1.5, 1.5, 0.5, 1.5, 1.5, 1. , 1.5, 1. ,\n",
       "        0.5, 0.5, 1. , 1.5, 1.5, 1.5, 1.5, 0.5, 1.5, 0.5, 1.5, 1. , 1.5,\n",
       "        0.5, 1. , 1.5, 1.5, 0.5, 1. , 1.5, 1.5, 1.5, 0.5, 1.5, 1.5, 0.5,\n",
       "        0.5, 1.5, 0.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 1.5, 1.5, 1.5,\n",
       "        1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 0.5, 1. , 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "        1.5, 1.5, 0.5, 1. , 1.5, 0.5, 0.5, 0.5, 1. , 1.5, 1.5, 0.5, 1.5,\n",
       "        1. , 1.5, 1.5, 0.5, 1.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1. , 1.5, 1.5,\n",
       "        0.5, 1.5, 1.5, 0.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1. , 1. , 1. ,\n",
       "        0.5, 0.5, 1.5, 0.5, 0.5, 0.5, 0.5, 1. , 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "        1. , 1.5, 1.5, 1.5, 0.5, 1.5, 0.5, 1. , 0.5, 1.5, 1. , 1.5, 1.5,\n",
       "        1.5, 0.5, 1.5, 1.5, 1.5, 1. , 1.5, 1.5, 0.5, 1.5, 1.5, 1. , 1. ,\n",
       "        0.5, 1.5, 1. , 1.5, 1.5, 1.5, 0.5, 1.5, 0.5, 0.5, 1.5, 1.5, 1.5,\n",
       "        0.5, 1.5, 0.5, 1.5, 1.5, 1.5, 0.5, 1. , 0.5, 0.5, 1.5, 1. , 1. ,\n",
       "        1.5, 0.5, 0.5, 1.5, 1.5, 1.5, 1. , 1.5, 1. , 1. , 1.5, 1.5, 0.5,\n",
       "        1.5, 1.5, 0.5, 1. , 0.5, 1. , 1.5, 1.5, 0.5, 1.5, 1. , 1.5, 0.5,\n",
       "        1.5, 1.5, 0.5, 1.5, 0.5, 1.5, 0.5, 0.5, 1.5, 1.5, 1.5, 1. , 1.5,\n",
       "        1. , 1.5, 1.5, 1.5, 0.5, 1.5, 1.5, 1.5, 1. , 1.5, 1. , 1.5, 1.5,\n",
       "        1. , 1.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1. , 0.5, 1. , 1. , 1.5,\n",
       "        0.5, 1.5, 1. , 1.5, 0.5, 0.5, 1.5, 0.5, 1. , 1.5, 0.5, 1.5, 1.5,\n",
       "        1.5, 1. , 0.5, 1.5, 1.5, 0.5, 1.5, 1.5, 1.5, 1. , 1.5, 1.5, 1. ,\n",
       "        1.5, 0.5, 0.5, 1. , 1. , 1. , 1.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1. ,\n",
       "        0.5, 1.5, 1.5, 0.5, 0.5, 1.5, 0.5, 1.5, 1.5, 1.5, 0.5, 1. , 1. ,\n",
       "        1.5, 1.5, 1.5, 1. , 0.5, 1. , 0.5, 1.5, 1.5, 0.5, 1.5, 1. , 1.5,\n",
       "        1.5, 1.5, 1.5, 0.5, 0.5, 1. , 1. , 1.5, 1. , 1. , 1.5, 1.5, 0.5,\n",
       "        1.5, 1.5, 1. , 1.5, 1.5, 1. , 1. , 1.5, 0.5, 0.5, 1.5, 1.5, 1. ,\n",
       "        0.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 1. , 1. , 1. , 1. , 1.5,\n",
       "        1.5, 0.5, 0.5, 1.5, 1.5, 1.5, 0.5, 1.5, 1.5, 1. , 0.5, 1.5, 1. ,\n",
       "        1.5, 1.5, 1.5, 1.5, 1.5, 0.5, 1.5, 1. , 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "        1.5, 1.5, 1.5, 1.5, 0.5, 1. , 1. , 1.5, 1.5, 0.5, 0.5, 1.5, 1. ,\n",
       "        1. , 1.5, 0.5, 0.5, 1.5, 0.5, 1.5, 0.5, 1. , 1.5, 1.5, 1.5, 0.5,\n",
       "        1.5, 1. , 1.5, 1.5, 1.5, 1.5, 1. , 0.5, 1. , 0.5, 1.5, 1.5, 1.5,\n",
       "        1.5, 1.5, 1.5, 1.5, 1. , 1.5, 1. , 1. , 1. , 1.5, 1.5, 1. , 1.5,\n",
       "        1.5, 0.5, 0.5, 1.5, 1. , 1.5, 0.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "        1.5, 1.5, 1. , 1.5, 1.5, 0.5, 0.5, 0.5, 1.5, 1.5, 0.5, 1.5, 0.5,\n",
       "        1.5, 0.5, 1. , 0.5, 1.5, 1.5, 0.5, 1.5, 1. , 1.5, 1.5, 1.5, 0.5,\n",
       "        0.5, 0.5, 1. , 1. , 1.5, 1.5, 1.5, 0.5, 1.5, 1.5, 0.5, 1.5, 1.5,\n",
       "        1.5, 0.5, 1. , 1.5, 1.5, 1.5, 1. , 1.5, 1. , 0.5], dtype=float32)>,\n",
       " 'SibSp': <tf.Tensor: shape=(712,), dtype=float32, numpy=\n",
       " array([0.125, 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.125,\n",
       "        0.125, 0.125, 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.125,\n",
       "        0.   , 0.   , 0.5  , 0.   , 0.   , 0.125, 0.   , 0.125, 0.   ,\n",
       "        0.125, 0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.25 , 0.   , 0.   , 0.   , 0.   , 0.125,\n",
       "        0.   , 0.125, 0.   , 0.   , 0.   , 0.125, 0.   , 0.   , 0.   ,\n",
       "        0.25 , 0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 1.   , 0.125,\n",
       "        0.375, 0.   , 0.   , 0.   , 1.   , 0.   , 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.125, 0.   , 0.125, 0.   , 0.125, 0.   , 0.375, 0.   ,\n",
       "        0.   , 0.   , 0.125, 0.125, 0.   , 0.   , 0.   , 0.   , 0.125,\n",
       "        0.   , 0.   , 0.   , 0.125, 0.125, 0.625, 0.   , 0.   , 0.   ,\n",
       "        0.125, 0.125, 0.125, 0.   , 0.   , 0.125, 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.125, 0.   , 0.125, 0.125, 0.   , 0.125,\n",
       "        0.25 , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.   , 0.5  , 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.   , 0.25 , 0.   , 0.   , 0.   , 0.125, 0.   , 0.   ,\n",
       "        0.125, 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.125, 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.125,\n",
       "        0.   , 0.125, 0.125, 0.   , 0.   , 0.   , 0.   , 0.625, 0.   ,\n",
       "        0.125, 0.   , 0.   , 0.375, 0.   , 0.   , 0.125, 0.125, 0.125,\n",
       "        0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.   ,\n",
       "        0.125, 0.125, 1.   , 0.5  , 0.125, 0.   , 0.5  , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.625, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.125, 0.375, 0.   , 0.   , 0.125, 0.   ,\n",
       "        0.125, 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.125, 0.   , 0.   , 0.125, 0.125, 0.125, 0.125, 0.   , 0.125,\n",
       "        0.25 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.375, 0.125, 0.375, 0.   , 0.125,\n",
       "        0.125, 0.   , 0.   , 0.   , 0.125, 0.125, 0.375, 0.   , 0.5  ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 0.125, 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.   ,\n",
       "        0.25 , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.375, 0.   , 0.   , 0.   , 0.   , 0.5  , 0.   , 0.   ,\n",
       "        0.125, 0.125, 0.   , 0.   , 0.   , 0.125, 0.   , 0.125, 0.125,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.   , 0.125, 0.   ,\n",
       "        0.25 , 0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.25 , 0.   , 0.   , 0.   , 0.125,\n",
       "        0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.25 ,\n",
       "        0.   , 0.   , 0.375, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.125, 0.125, 0.   , 0.5  , 0.   , 0.25 , 0.   , 0.   ,\n",
       "        0.   , 0.125, 0.375, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.5  , 0.   , 0.   , 0.   , 0.   , 0.   , 0.25 , 0.   , 0.125,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.125, 0.125, 1.   , 0.125, 0.   ,\n",
       "        0.   , 0.125, 0.125, 0.   , 0.   , 0.125, 0.   , 0.   , 0.125,\n",
       "        0.25 , 0.   , 0.   , 0.   , 0.   , 0.125, 0.5  , 0.   , 0.   ,\n",
       "        0.125, 0.   , 0.   , 0.   , 0.25 , 0.125, 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.125, 0.125, 0.   , 0.   , 0.125, 0.125, 0.25 , 0.125, 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.125, 0.125, 0.   , 0.125, 0.375, 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.5  , 0.   ,\n",
       "        0.   , 0.125, 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.5  , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.125, 0.   , 0.125, 0.   , 0.5  , 0.   , 0.   , 0.   , 0.125,\n",
       "        0.   , 0.25 , 0.   , 0.   , 0.   , 0.125, 0.125, 0.125, 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.125, 0.   , 0.125, 0.   , 0.   , 0.   ,\n",
       "        0.5  , 0.   , 0.   , 0.   , 0.125, 0.125, 0.   , 0.   , 0.   ,\n",
       "        0.25 , 0.25 , 0.25 , 0.   , 0.   , 0.5  , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 1.   , 0.   , 0.   , 0.   , 0.125, 0.125, 0.25 ,\n",
       "        0.   , 0.   , 0.125, 0.   , 0.125, 0.   , 0.25 , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.125, 0.125, 0.   , 0.   , 0.   , 0.125,\n",
       "        0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.5  , 0.   ,\n",
       "        0.125, 0.   , 0.   , 0.125, 0.125, 0.125, 0.125, 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.125, 0.   , 0.   , 0.125, 0.   , 0.125,\n",
       "        0.   , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.125, 0.   , 0.125, 0.   , 0.125, 0.   , 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.125, 0.   , 0.   , 0.125, 0.   , 0.   , 0.125, 0.   ,\n",
       "        0.   , 0.125, 0.   , 0.   , 0.125, 0.125, 0.   , 0.125, 0.25 ,\n",
       "        0.125, 0.375, 0.   , 0.125, 0.   , 0.625, 0.   , 0.   , 0.5  ,\n",
       "        0.125, 0.   , 0.25 , 0.125, 0.   , 0.   , 0.125, 0.   , 0.   ,\n",
       "        0.   ], dtype=float32)>,\n",
       " 'Parch': <tf.Tensor: shape=(712,), dtype=float32, numpy=\n",
       " array([0.        , 0.33333334, 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.33333334, 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.16666667, 0.        , 0.16666667, 0.16666667,\n",
       "        0.6666667 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333334, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.33333334, 0.        , 0.        ,\n",
       "        0.        , 0.33333334, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.33333334, 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.16666667, 0.6666667 , 0.        , 0.33333334,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333334, 0.16666667, 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.33333334,\n",
       "        0.33333334, 0.        , 0.33333334, 0.16666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.8333333 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "        0.        , 0.16666667, 0.33333334, 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
       "        0.33333334, 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.16666667, 0.        , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       , 0.16666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.6666667 , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16666667, 0.33333334,\n",
       "        0.        , 0.33333334, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.33333334, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333334, 0.16666667,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.16666667, 0.8333333 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16666667, 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.8333333 , 0.        , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333334, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.33333334, 0.        ,\n",
       "        0.33333334, 0.        , 0.16666667, 0.16666667, 0.        ,\n",
       "        0.        , 0.16666667, 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333334, 0.33333334,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.33333334,\n",
       "        0.        , 0.        , 0.33333334, 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.33333334, 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.16666667, 0.33333334, 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.33333334, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333334, 0.        , 0.        ,\n",
       "        0.        , 0.33333334, 0.        , 0.        , 0.33333334,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16666667, 0.        , 0.16666667, 0.        ,\n",
       "        0.16666667, 0.        , 0.33333334, 0.        , 0.        ,\n",
       "        0.16666667, 0.16666667, 0.        , 0.        , 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.8333333 ,\n",
       "        0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333334, 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.33333334, 0.        , 0.        ,\n",
       "        0.        , 0.16666667, 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.        , 0.16666667, 0.33333334, 0.16666667, 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.8333333 , 0.16666667,\n",
       "        0.16666667, 0.33333334, 0.        , 0.        , 0.33333334,\n",
       "        0.        , 0.        , 0.33333334, 0.33333334, 0.        ,\n",
       "        0.33333334, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.16666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.5       , 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16666667, 0.33333334,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333334, 0.33333334,\n",
       "        0.        , 0.        , 0.33333334, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16666667,\n",
       "        0.        , 0.        , 0.        , 0.33333334, 0.        ,\n",
       "        0.        , 0.33333334, 0.16666667, 0.16666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ], dtype=float32)>,\n",
       " 'Fare': <tf.Tensor: shape=(712,), dtype=float32, numpy=\n",
       " array([0.02194234, 0.2958059 , 0.01376888, 0.11027245, 0.02537431,\n",
       "        0.03806146, 0.4440992 , 0.02042144, 0.04994347, 0.05182214,\n",
       "        0.01415106, 0.01415106, 0.02049463, 0.0150944 , 0.02173075,\n",
       "        0.04713766, 0.01361429, 0.05074862, 0.03093714, 0.02975782,\n",
       "        0.09661756, 0.01375249, 0.01522459, 0.02821272, 0.01521639,\n",
       "        0.01571255, 0.15546644, 0.0541074 , 0.4831284 , 0.05684821,\n",
       "        0.04113566, 0.01537917, 0.11111839, 0.02537431, 0.03025398,\n",
       "        0.05182214, 0.2958059 , 0.01541157, 0.15216446, 0.17777476,\n",
       "        0.06764049, 0.02635024, 0.14891148, 0.06640418, 0.06538764,\n",
       "        0.01571255, 0.01541157, 0.01541157, 0.06709553, 0.05074862,\n",
       "        0.01921772, 0.02049463, 0.0150944 , 0.07173122, 0.16883674,\n",
       "        0.01533038, 0.01592394, 0.02049463, 0.01571255, 0.16293234,\n",
       "        0.16231419, 0.01571255, 0.01588334, 0.01690807, 0.01217479,\n",
       "        0.        , 0.01411046, 0.01854276, 0.4440992 , 0.0541074 ,\n",
       "        0.13575256, 0.10364429, 0.5133418 , 0.11027245, 0.01512699,\n",
       "        0.01411046, 0.13575256, 0.01854276, 0.02537431, 0.1756683 ,\n",
       "        0.14346243, 0.02049463, 0.05123658, 0.16883674, 0.05074862,\n",
       "        0.        , 0.10149723, 0.01541157, 0.05445717, 0.01537917,\n",
       "        0.06050797, 0.01546857, 0.02821272, 0.02810693, 0.01571255,\n",
       "        0.01571255, 0.02830211, 0.01533038, 0.07612292, 0.02537431,\n",
       "        0.01517579, 0.4125033 , 0.05445717, 0.1756683 , 0.0915427 ,\n",
       "        0.01690807, 0.01473662, 0.02537431, 0.14976542, 0.14687821,\n",
       "        0.04713766, 0.02049463, 0.01571255, 0.02821272, 0.01854276,\n",
       "        0.2958059 , 0.07690368, 0.01546857, 0.06929138, 0.02635024,\n",
       "        0.01411046, 0.02049463, 0.22109807, 0.05074862, 0.05123658,\n",
       "        0.05416439, 0.01546857, 0.02830211, 0.01411046, 0.02537431,\n",
       "        0.03025398, 0.02635024, 0.01376068, 0.01415106, 0.13526459,\n",
       "        0.02937564, 0.01571255, 0.01541157, 0.01338651, 0.11027245,\n",
       "        0.05684821, 0.01646071, 0.04006213, 0.05182214, 0.01517579,\n",
       "        0.11316785, 0.14346243, 0.01571255, 0.02049463, 0.01537917,\n",
       "        0.01917712, 0.01376068, 0.01512699, 0.10257896, 0.06929138,\n",
       "        0.06104473, 0.01411046, 0.01571255, 0.01546857, 1.        ,\n",
       "        0.2958059 , 0.02537431, 0.04713766, 0.05060223, 0.03103473,\n",
       "        0.00975935, 0.01541157, 0.05074862, 0.01512699, 0.06343577,\n",
       "        0.02537431, 0.05074862, 0.03072575, 0.01463083, 0.11940564,\n",
       "        0.01521639, 0.03142511, 0.01571255, 0.01690807, 0.02830211,\n",
       "        0.01411046, 0.03035158, 0.06709553, 0.01411046, 0.02537431,\n",
       "        0.06831545, 0.16231419, 0.0915427 , 0.01546857, 0.12999453,\n",
       "        0.03259623, 0.01512699, 0.04098927, 0.02537431, 0.09759349,\n",
       "        0.05074862, 0.0915427 , 0.04684488, 0.01489121, 0.16038671,\n",
       "        0.03945217, 0.01533038, 0.10149723, 0.01546857, 0.02821272,\n",
       "        0.05182214, 0.05061042, 0.04098927, 0.05074862, 0.13575256,\n",
       "        0.06104473, 0.10821499, 0.        , 0.07746483, 0.01541157,\n",
       "        0.01411046, 0.03806146, 0.01571255, 0.0915427 , 0.01512699,\n",
       "        0.01920152, 0.02537431, 0.01824998, 0.01533038, 0.01571255,\n",
       "        0.01583455, 0.20772776, 0.05182214, 0.10364429, 0.5133418 ,\n",
       "        0.01854276, 0.05182214, 0.03474328, 0.01512699, 0.04006213,\n",
       "        0.03659756, 0.02049463, 0.0239592 , 0.01512699, 0.01521639,\n",
       "        0.01541157, 0.05797054, 0.01317512, 0.01571255, 0.04684488,\n",
       "        0.01512699, 0.02049463, 0.        , 0.05061042, 0.02537431,\n",
       "        0.01267896, 0.01415106, 0.01517579, 0.0375897 , 0.4831284 ,\n",
       "        0.04713766, 0.05416439, 0.01512699, 0.02537431, 0.01517579,\n",
       "        0.06050797, 0.05074862, 0.01376068, 0.04298994, 0.22109807,\n",
       "        0.05270049, 0.03142511, 0.05445717, 0.01690807, 0.11125658,\n",
       "        0.0375897 , 0.01690807, 0.29953882, 0.4125033 , 0.01571255,\n",
       "        0.0585561 , 0.26473856, 0.02042144, 0.01541157, 0.01567195,\n",
       "        0.01541157, 0.01410226, 0.05953203, 0.04970768, 0.04713766,\n",
       "        0.05445717, 0.01517579, 0.0389724 , 0.03142511, 0.01361429,\n",
       "        0.01571255, 0.05797054, 0.14976542, 0.05660423, 0.05445717,\n",
       "        0.01571255, 0.06126432, 0.01541157, 0.        , 0.0150944 ,\n",
       "        0.01871355, 0.05991421, 0.06441171, 0.03474328, 0.20772776,\n",
       "        0.11111839, 0.10122886, 0.02049463, 0.02434958, 0.01521639,\n",
       "        0.12097533, 0.01571255, 0.08115719, 0.01546857, 0.03667076,\n",
       "        0.1004807 , 0.02822072, 0.05182214, 0.04364049, 0.02618765,\n",
       "        0.0179898 , 0.01541157, 0.03659756, 0.01541157, 0.11027245,\n",
       "        0.5133418 , 0.01512699, 0.01571255, 0.05182214, 0.0585561 ,\n",
       "        0.06126432, 0.11027245, 0.01512699, 0.02173075, 0.06126432,\n",
       "        0.02049463, 0.02537431, 0.        , 0.15216446, 0.0585561 ,\n",
       "        0.01376888, 0.15458809, 0.08275929, 0.13526459, 0.4440992 ,\n",
       "        0.02469115, 0.01546857, 0.01410226, 0.01541157, 0.01415106,\n",
       "        0.02830211, 0.07612292, 0.01376068, 0.01541157, 0.01533038,\n",
       "        0.12366716, 0.06104473, 0.06929138, 0.08115719, 0.05130978,\n",
       "        0.01258956, 0.02537431, 0.        , 0.01493181, 0.01411046,\n",
       "        0.10122886, 0.01512699, 0.01662349, 0.01512699, 0.02049463,\n",
       "        0.01517579, 0.01571255, 0.05182214, 0.03513366, 0.03142511,\n",
       "        0.03074195, 0.05074862, 0.10149723, 0.01546857, 0.05074862,\n",
       "        0.01571255, 0.01571255, 0.01571255, 0.05182214, 0.03025398,\n",
       "        0.15085514, 0.26086742, 0.01541157, 0.01508639, 0.03093714,\n",
       "        0.05074862, 0.02975782, 0.0585561 , 0.01390707, 0.04713766,\n",
       "        0.01410226, 0.05182214, 0.07173122, 0.2342244 , 0.14976542,\n",
       "        0.06104473, 0.02537431, 0.0224465 , 0.02434958, 0.10149723,\n",
       "        0.21642978, 0.02173075, 0.04970768, 0.0150782 , 0.0224465 ,\n",
       "        0.01690807, 0.02537431, 0.05074862, 0.01756683, 0.05684821,\n",
       "        0.05604307, 0.01517579, 0.01541157, 0.05182214, 0.02049463,\n",
       "        0.51212186, 0.02049463, 0.03945217, 0.01571255, 0.05991421,\n",
       "        0.01541157, 0.0224465 , 0.01917712, 0.2342244 , 0.13575256,\n",
       "        0.02830211, 0.075147  , 0.02434958, 0.1756683 , 0.03025398,\n",
       "        0.09856123, 0.06929138, 0.02821272, 0.01512699, 0.01467962,\n",
       "        0.05416439, 0.04713766, 0.02537431, 0.01571255, 0.03072575,\n",
       "        0.04396587, 0.28598952, 0.06104473, 0.01533038, 0.01541157,\n",
       "        0.05074862, 0.01410226, 0.05123658, 0.02822072, 0.03513366,\n",
       "        0.12687154, 0.01632251, 0.11594108, 0.01541157, 0.01541157,\n",
       "        0.01493181, 0.01512699, 0.01537917, 0.02537431, 0.2625265 ,\n",
       "        0.02049463, 0.        , 0.01700567, 0.4440992 , 0.0165095 ,\n",
       "        0.07222738, 0.02830211, 0.21642978, 0.07729404, 0.01541157,\n",
       "        0.15546644, 0.02537431, 0.01393967, 0.17391981, 0.01512699,\n",
       "        0.01493181, 0.01390707, 0.02537431, 0.05150497, 0.01473662,\n",
       "        0.01512699, 0.21255864, 0.04713766, 0.01920972, 0.018006  ,\n",
       "        0.05123658, 0.04015972, 0.04231498, 0.05074862, 0.01512699,\n",
       "        0.05182214, 0.06050797, 0.05074862, 0.05074862, 0.0585561 ,\n",
       "        0.01571255, 0.10910953, 0.05445717, 0.01517579, 0.01411046,\n",
       "        0.01690807, 0.0270578 , 0.22109807, 0.01511079, 0.01410226,\n",
       "        0.10149723, 0.21642978, 0.01571255, 0.09662576, 0.04006213,\n",
       "        0.01517579, 0.01376068, 0.0541074 , 0.05074862, 0.02537431,\n",
       "        0.07746483, 0.01411046, 0.01571255, 0.0224465 , 0.18249984,\n",
       "        0.02537431, 0.05182214, 0.01571255, 0.01517579, 0.05797054,\n",
       "        0.01411046, 0.04489301, 0.01854276, 0.03025398, 0.11027245,\n",
       "        0.02821272, 0.16883674, 0.13858277, 0.02732618, 0.06441171,\n",
       "        0.07746483, 0.05074862, 0.02537431, 0.01517579, 0.01510259,\n",
       "        0.32179835, 0.01541157, 0.01541157, 0.04098927, 0.07746483,\n",
       "        0.01512699, 0.04489301, 0.03122992, 0.01493181, 0.09662576,\n",
       "        0.18249984, 0.01512699, 0.01512699, 0.04098927, 0.29953882,\n",
       "        0.17777476, 0.01415106, 0.06104473, 0.01690807, 0.01463083,\n",
       "        0.018006  , 0.16231419, 0.02537431, 0.05270049, 0.02513033,\n",
       "        0.02049463, 0.01512699, 0.03025398, 0.32179835, 0.15276642,\n",
       "        0.01541157, 0.01571255, 0.01546857, 0.43288416, 0.02975782,\n",
       "        0.01541157, 0.07612292, 0.05130158, 0.02434958, 0.02444717,\n",
       "        0.01546857, 0.01410226, 0.01851017, 0.01533038, 0.03093714,\n",
       "        0.13913573, 0.01415106, 0.02410559, 0.05684821, 0.0375897 ,\n",
       "        0.0375897 , 0.06709553, 0.01415106, 0.01517579, 0.06104473,\n",
       "        0.01512699, 0.02947324, 0.4128205 , 0.02537431, 0.02537431,\n",
       "        0.13575256, 0.01410226, 0.        , 0.15458809, 0.03142511,\n",
       "        0.05074862, 0.07612292, 0.01571255, 0.1561496 , 0.10910953,\n",
       "        0.01463083, 0.26086742, 0.01473662, 0.51212186, 0.02537431,\n",
       "        0.01689187, 0.01520019, 0.01571255, 0.05074862, 0.03259623,\n",
       "        0.05074862, 0.01985208, 0.01756683, 0.01410226, 0.03396254,\n",
       "        0.04489301, 0.05130978, 0.02936745, 0.        , 0.01415106,\n",
       "        0.01517579, 0.01571255, 0.07746483, 0.        , 0.03513366,\n",
       "        0.02052723, 0.02410559, 0.06709553, 0.05074862, 0.05123658,\n",
       "        0.04098927, 0.01546857, 0.01571255, 0.02049463, 0.01541157,\n",
       "        0.01390707, 0.10149723, 0.063086  , 0.0164039 , 0.08115719,\n",
       "        0.01512699, 0.11125658, 0.01854276, 0.01690807, 0.0389724 ,\n",
       "        0.01512699, 0.01541157, 0.01390707, 0.01533038, 0.01376068,\n",
       "        0.02049463, 0.01267896, 0.01512699, 0.15216446, 1.        ,\n",
       "        0.10364429, 0.01854276, 0.01256516, 0.13858277, 0.01533038,\n",
       "        0.15458809, 0.03142511, 0.28598952, 0.05074862, 0.2342244 ,\n",
       "        0.01727405, 0.01541157, 0.2342244 , 0.01854276, 0.02635024,\n",
       "        0.03142511, 0.01512699, 0.01517579, 0.10149723, 0.12999453,\n",
       "        0.26473856, 0.04098927, 0.14346243, 0.01517579, 0.04113566,\n",
       "        0.01541157, 0.10364429, 0.01690807, 0.0915427 , 0.0541074 ,\n",
       "        0.01427305, 0.06126432, 0.03952537, 0.4125033 , 0.14346243,\n",
       "        0.01546857, 0.01571255, 0.01571255, 0.05074862, 0.01541157,\n",
       "        0.02537431, 0.        ], dtype=float32)>,\n",
       " 'Sex': <tf.Tensor: shape=(712,), dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "        1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " 'Ticket': <tf.Tensor: shape=(712,), dtype=float32, numpy=\n",
       " array([186.,  37., 345.,  80., 154., 162., 610., 316., 496.,  44., 272.,\n",
       "        525., 553., 419., 344., 307., 338., 100., 247., 189.,  75., 315.,\n",
       "        522., 211., 402., 429.,   1., 604., 585., 480., 395., 282., 584.,\n",
       "        220., 444.,  11.,  37., 359.,  71.,  64., 607., 108.,  63., 456.,\n",
       "          5., 517., 391., 367., 676., 139., 504., 146., 534., 558.,   0.,\n",
       "        406., 623., 557., 654., 457.,  59., 540., 281., 270., 299., 135.,\n",
       "        202., 305., 610., 601., 568.,  49.,  95.,  80., 321., 178., 568.,\n",
       "        310., 134.,  92., 621., 550., 556.,   0., 127., 137.,  99., 368.,\n",
       "        337., 283.,  47., 662., 204., 331., 475., 295., 538., 343., 240.,\n",
       "        105., 397., 141., 337.,  93., 566., 269., 620., 223., 587.,   4.,\n",
       "        307., 546., 473., 188., 306.,  37., 591., 666.,  69., 128., 214.,\n",
       "        549., 416., 144., 571., 561., 246., 166., 210., 122., 440., 156.,\n",
       "        650., 524., 581., 629., 424., 352., 487.,  80., 480., 512., 423.,\n",
       "         52., 319.,   7., 621., 653., 674., 285., 491., 641., 436.,  56.,\n",
       "         39., 333., 215., 425., 659., 608.,  37., 151., 519., 576., 562.,\n",
       "        502., 387., 170., 481., 224., 219., 139., 187., 243., 678., 410.,\n",
       "        495.,  79., 260., 166., 191., 396., 676., 212., 147.,  30.,  59.,\n",
       "        566., 647.,  36., 616., 465., 252., 229.,  34., 180., 566., 575.,\n",
       "        276., 600., 458., 341.,   2., 671., 193.,  48.,  88., 230., 626.,\n",
       "        568., 333.,  58.,  97., 249., 370., 208., 162., 510., 566., 446.,\n",
       "        509., 228., 615., 415., 515., 499., 614.,  19.,  51.,  95., 313.,\n",
       "         73., 377., 467., 423., 237., 619., 636.,  66., 401., 386., 594.,\n",
       "        439., 431., 575.,  76., 560.,  16.,  87., 112., 242., 649., 327.,\n",
       "        194., 585., 469.,  22., 464., 241., 336.,  47., 144., 643., 271.,\n",
       "        416., 142., 476., 337., 262.,  89., 194., 268., 588., 141., 427.,\n",
       "         14., 613., 316., 358., 278., 388., 192.,  40., 488., 469., 337.,\n",
       "        322., 497., 536., 318., 516.,  62., 587., 158., 337., 539., 329.,\n",
       "        365., 574., 286., 490., 597., 155., 377., 614., 584.,  85., 555.,\n",
       "        432., 403.,  29., 514., 634., 655., 216.,  60., 209.,  21., 196.,\n",
       "        393., 504., 354., 237., 349.,  80.,  95., 513., 529.,   9., 218.,\n",
       "        329.,  80., 332., 344., 329., 231., 163., 136.,  71.,  82., 408.,\n",
       "         74.,  46., 581., 610., 140., 667., 184., 375., 523., 426., 114.,\n",
       "        638., 364., 400., 612., 333.,  94., 634., 579., 543., 552., 574.,\n",
       "        348., 217.,  86., 290., 174., 461., 222., 323., 528.,   3., 302.,\n",
       "        495., 559., 226.,  43., 669., 627., 298., 651., 527.,  31., 459.,\n",
       "        417., 605., 361., 447., 247., 501., 203.,   8., 656., 469., 195.,\n",
       "         23., 558.,  33., 587., 333., 164., 235., 486.,   2.,  83., 344.,\n",
       "        488., 421., 238., 266., 227., 170., 304., 480., 593., 335., 371.,\n",
       "         10., 572., 602., 619., 458., 645.,  90., 373., 118., 492.,  33.,\n",
       "        568., 537.,   6., 432.,  93., 459., 590.,  42., 188., 287., 411.,\n",
       "        561., 519., 225., 518., 187., 542., 586., 333., 342., 390., 113.,\n",
       "        177., 556., 176., 302., 106., 511., 599., 369., 366., 346., 478.,\n",
       "        279.,  65.,  81., 673., 138., 291., 610., 275., 618., 420.,  83.,\n",
       "         18., 385.,   1., 165., 541.,  84., 482., 296., 657., 169., 578.,\n",
       "        567.,  78., 611., 307., 493., 503., 571., 548., 190., 167., 288.,\n",
       "         45.,  17., 115., 150., 133., 533.,  72., 337., 254., 206., 267.,\n",
       "        631., 416., 449., 171.,  99.,  83., 652., 582., 423., 324., 642.,\n",
       "        606., 148., 120., 249., 181., 644., 221.,  67., 119.,  96., 535.,\n",
       "        255.,  61., 207., 117., 308., 435.,  80., 211.,   0., 680., 232.,\n",
       "        155., 249., 115., 149., 256., 451., 453., 389., 382., 570., 249.,\n",
       "         77., 236., 153., 347., 603.,  67., 445., 434.,  53., 588.,  64.,\n",
       "        526., 333., 263., 356., 500., 609., 145., 142., 635., 547., 466.,\n",
       "        462., 453., 454., 380., 485., 663., 583., 203., 351., 240.,  55.,\n",
       "        486., 622., 248., 179., 506., 414., 668., 596., 521., 104., 480.,\n",
       "        194., 194., 676., 422., 317., 333., 452., 564.,  27., 168., 257.,\n",
       "        568., 182.,  13., 589., 536., 113., 114., 520.,  32.,  72., 357.,\n",
       "        605., 677., 602., 157., 505., 280., 472.,  24., 616., 233., 372.,\n",
       "        303., 213., 300., 234., 580., 630.,  12., 544., 320., 531., 249.,\n",
       "        574., 301., 508., 109., 676., 198., 571.,  53., 250., 617., 637.,\n",
       "        360., 646., 569., 455., 494., 634., 460.,  89., 311., 264., 498.,\n",
       "        442., 379., 658., 413., 639., 253., 244., 468.,  71., 608.,  49.,\n",
       "        309., 205., 680., 409., 592., 477., 586., 180.,  33., 376., 355.,\n",
       "         33., 312., 103., 476., 479., 325.,  43.,  36., 613., 252., 621.,\n",
       "        328., 395., 350.,  35., 258., 566., 598., 573., 329., 551., 141.,\n",
       "        621., 660., 273., 530., 239., 374., 161.,  15.], dtype=float32)>,\n",
       " 'Embarked': <tf.Tensor: shape=(712,), dtype=float32, numpy=\n",
       " array([0., 3., 3., 3., 3., 3., 0., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3.,\n",
       "        3., 3., 0., 0., 3., 3., 0., 3., 3., 3., 0., 0., 2., 3., 2., 0., 3.,\n",
       "        2., 3., 3., 0., 3., 0., 0., 3., 0., 3., 3., 3., 0., 3., 3., 3., 3.,\n",
       "        3., 2., 3., 3., 3., 3., 3., 3., 3., 0., 3., 2., 3., 3., 3., 0., 3.,\n",
       "        0., 0., 3., 3., 3., 3., 3., 0., 3., 3., 3., 2., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 2., 3., 3., 0., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 0., 0., 3., 3., 3., 0., 3., 3., 3., 3., 0.,\n",
       "        3., 0., 3., 0., 3., 3., 3., 3., 3., 0., 3., 2., 3., 3., 3., 0., 0.,\n",
       "        3., 3., 2., 3., 2., 3., 3., 3., 3., 0., 3., 3., 3., 2., 3., 3., 2.,\n",
       "        3., 3., 3., 0., 3., 3., 0., 3., 3., 3., 3., 3., 3., 3., 3., 2., 3.,\n",
       "        3., 3., 0., 3., 3., 3., 3., 3., 3., 3., 0., 3., 3., 0., 3., 3., 0.,\n",
       "        3., 3., 3., 3., 2., 3., 3., 3., 3., 3., 0., 2., 0., 3., 3., 3., 3.,\n",
       "        0., 3., 3., 3., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3., 3., 2., 3.,\n",
       "        3., 3., 3., 3., 3., 0., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 3.,\n",
       "        2., 3., 3., 0., 2., 3., 0., 2., 3., 3., 3., 3., 3., 3., 3., 0., 0.,\n",
       "        2., 0., 2., 3., 3., 0., 3., 3., 3., 0., 3., 3., 3., 3., 3., 0., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 2., 3., 0., 3., 3., 2., 3., 3., 3., 3.,\n",
       "        3., 3., 0., 0., 3., 3., 3., 3., 3., 3., 2., 3., 0., 3., 3., 0., 0.,\n",
       "        3., 3., 3., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 0., 3., 3., 3.,\n",
       "        3., 3., 3., 2., 3., 0., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 0., 3., 0., 0., 3., 3., 0., 3., 3., 3., 3., 3., 3., 3., 0., 3.,\n",
       "        3., 0., 3., 3., 3., 3., 3., 0., 3., 2., 0., 2., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 2., 3., 3.,\n",
       "        0., 0., 3., 2., 0., 3., 3., 3., 0., 3., 3., 3., 3., 3., 0., 3., 3.,\n",
       "        2., 3., 3., 3., 3., 3., 2., 0., 3., 3., 3., 3., 0., 3., 3., 3., 0.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 3., 2., 3., 3., 0., 2., 3., 3., 3.,\n",
       "        3., 3., 0., 3., 0., 3., 3., 3., 3., 0., 3., 0., 3., 3., 3., 0., 3.,\n",
       "        3., 3., 2., 2., 3., 0., 3., 3., 0., 0., 2., 0., 3., 0., 0., 3., 3.,\n",
       "        3., 3., 0., 2., 3., 3., 3., 3., 3., 2., 0., 3., 3., 3., 3., 3., 0.,\n",
       "        3., 2., 3., 0., 3., 3., 3., 3., 3., 3., 3., 0., 3., 0., 0., 2., 0.,\n",
       "        3., 0., 3., 0., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 0., 0., 3., 3., 2., 3., 0., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        2., 3., 3., 3., 3., 3., 2., 3., 3., 3., 0., 3., 2., 2., 3., 3., 0.,\n",
       "        3., 3., 3., 3., 3., 0., 3., 3., 0., 3., 2., 2., 3., 0., 0., 3., 3.,\n",
       "        3., 0., 3., 3., 3., 3., 3., 3., 0., 3., 3., 3., 0., 3., 2., 2., 0.,\n",
       "        0., 3., 3., 3., 3., 2., 3., 0., 3., 3., 3., 0., 3., 0., 3., 3., 3.,\n",
       "        3., 1., 3., 3., 3., 3., 0., 3., 3., 2., 3., 3., 3., 3., 3., 3., 0.,\n",
       "        3., 3., 3., 0., 3., 3., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 0., 2., 3., 3., 3., 3., 2., 0., 3.,\n",
       "        3., 3., 3., 3., 2., 3., 0., 3., 3., 0., 3., 3., 0., 3., 0., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 0., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 0., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "       dtype=float32)>}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_AI_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_AI_2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_transforming_function(data):\n",
    "\n",
    "    for i in enumerate(data.keys()):\n",
    "        if (i[0]==0):\n",
    "            temp=(np.array(data[i[1]]))\n",
    "            n=len(temp)\n",
    "        else:\n",
    "            new_temp=np.array(data[i[1]])\n",
    "            temp = np.concatenate([temp,new_temp],axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    temp0=(temp.reshape((len(data.keys()),n)).T)\n",
    "    return temp0\n",
    "# labels=[]\n",
    "# labels.append(np.array(y_AI_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new=array_transforming_function(x_AI_2)\n",
    "labels=np.array(y_AI_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_test=array_transforming_function(x_AI_2_test)\n",
    "labels_test=np.array(y_AI_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 9)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in X_train_ANN_f:\n",
    "#     print(i[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=80\n",
    "BATCH_SIZE=3\n",
    "\n",
    "# model = Modelo_IA(num_classes=1)\n",
    "# model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9,nesterov=True),\n",
    "#               metrics=['Recall','Precision'],\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "#               )\n",
    "\n",
    "# model.fit(x_new,labels,batch_size=BATCH_SIZE,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_hp(hp):\n",
    "    hp_units0_0=hp.Int('units_0_0',min_value=0,max_value=1024,step=512)\n",
    "    hp_units0=hp.Int('units_0',min_value=0,max_value=512,step=256)\n",
    "    hp_units1=hp.Int('units_1',min_value=0,max_value=256,step=128)\n",
    "    hp_units2=hp.Int('units_2',min_value=0,max_value=128,step=64)\n",
    "    hp_units3=hp.Int('units_3',min_value=0,max_value=64,step=32)\n",
    "    hp_drop0_0=hp.Float('drop_0_0',min_value=0.0,max_value=0.6,step=0.1)\n",
    "    hp_drop0=hp.Float('drop_0',min_value=0.0,max_value=0.6,step=0.1)\n",
    "    hp_drop1=hp.Float('drop_1',min_value=0.0,max_value=0.6,step=0.1)\n",
    "    hp_drop2=hp.Float('drop_2',min_value=0.0,max_value=0.6,step=0.1)\n",
    "    hp_drop3=hp.Float('drop_3',min_value=0.0,max_value=0.6,step=0.1)\n",
    "\n",
    "    model=Modelo_IA(num_classes=1,hp_units0_0=hp_units0_0,hp_units0=hp_units0,hp_units1=hp_units1,hp_units2=hp_units2,hp_units3=hp_units3,\n",
    "                    hp_drop0_0=hp_drop0_0,hp_drop0=hp_drop0,hp_drop1=hp_drop1,hp_drop2=hp_drop2,hp_drop3=hp_drop3)\n",
    "    hp_learning_rate=hp.Choice('learning_rate',values=[1e-2,2e-2,3e-2,4e-2,5e-2,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8])\n",
    "    hp_BETA1=hp.Choice('beta1',values=[0.85,0.9,0.95])\n",
    "    hp_BETA2=hp.Choice('beta2',values=[0.9,0.95,0.99])\n",
    "    # hp_momentum=hp.Choice('momentum',values=[0.85,0.9,0.95,0.99])\n",
    "    # model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=hp_learning_rate,momentum=hp_momentum),\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate,beta_1=hp_BETA1,beta_2=hp_BETA2),\n",
    "                  metrics=['Recall','Precision','AUC'],\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "                  )\n",
    "    return model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_auc',patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_hp,\n",
    "    objective=kt.Objective(name='val_auc',direction='max'),\n",
    "    max_epochs=EPOCHS,\n",
    "    project_name='model_all_data4',\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 01m 21s]\n",
      "val_auc: 0.5\n",
      "\n",
      "Best val_auc So Far: 0.8373968005180359\n",
      "Total elapsed time: 00h 27m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_new,labels,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(x_new_test,labels_test),validation_steps=35,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 1024,256, 256 , 128 , 64,0.4  ,0.4 ,0.30000000000000004 , 0.30000000000000004 , 0.0,  and the optimal learning rate for the optimizer\n",
      "is 0.04, the beta1 selected was 0.95, the beta2 selected was 0.9 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units_0_0')},{best_hps.get('units_0')}, {best_hps.get('units_1')} , {best_hps.get('units_2')} , {best_hps.get('units_3')},{best_hps.get('drop_0_0')}  ,{best_hps.get('drop_0')} ,{best_hps.get('drop_1')} , {best_hps.get('drop_2')} , {best_hps.get('drop_3')},  and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}, the beta1 selected was {best_hps.get('beta1')}, the beta2 selected was {best_hps.get('beta2')} .\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "(None, 9)\n",
      "(None, 9)\n",
      "232/238 [============================>.] - ETA: 0s - loss: 0.7312 - recall: 0.2895 - precision: 0.4162 - auc: 0.5311(None, 9)\n",
      "238/238 [==============================] - 4s 5ms/step - loss: 0.7302 - recall: 0.2831 - precision: 0.4162 - auc: 0.5312 - val_loss: 0.7020 - val_recall: 0.0698 - val_precision: 0.6000 - val_auc: 0.5910\n",
      "Epoch 2/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6763 - recall: 0.2132 - precision: 0.4328 - auc: 0.5544 - val_loss: 0.6846 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5895\n",
      "Epoch 3/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6731 - recall: 0.2096 - precision: 0.4634 - auc: 0.5704 - val_loss: 0.6805 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5930\n",
      "Epoch 4/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6776 - recall: 0.1728 - precision: 0.4393 - auc: 0.5557 - val_loss: 0.6841 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.4032\n",
      "Epoch 5/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6731 - recall: 0.2610 - precision: 0.4671 - auc: 0.5733 - val_loss: 0.7239 - val_recall: 0.3488 - val_precision: 0.6818 - val_auc: 0.5941\n",
      "Epoch 6/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6732 - recall: 0.2132 - precision: 0.4496 - auc: 0.5723 - val_loss: 0.7009 - val_recall: 0.0698 - val_precision: 0.6000 - val_auc: 0.5960\n",
      "Epoch 7/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6793 - recall: 0.2132 - precision: 0.4462 - auc: 0.5667 - val_loss: 0.6662 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5962\n",
      "Epoch 8/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6782 - recall: 0.1838 - precision: 0.4098 - auc: 0.5484 - val_loss: 0.6881 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5964\n",
      "Epoch 9/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6788 - recall: 0.1507 - precision: 0.3534 - auc: 0.5557 - val_loss: 0.6952 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5970\n",
      "Epoch 10/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6746 - recall: 0.2684 - precision: 0.4932 - auc: 0.5740 - val_loss: 0.6836 - val_recall: 0.2093 - val_precision: 0.7500 - val_auc: 0.5990\n",
      "Epoch 11/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6692 - recall: 0.1949 - precision: 0.4274 - auc: 0.5811 - val_loss: 0.6803 - val_recall: 0.0465 - val_precision: 1.0000 - val_auc: 0.5996\n",
      "Epoch 12/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6686 - recall: 0.2059 - precision: 0.4409 - auc: 0.5741 - val_loss: 0.6821 - val_recall: 0.1163 - val_precision: 0.7143 - val_auc: 0.6007\n",
      "Epoch 13/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6736 - recall: 0.1618 - precision: 0.4190 - auc: 0.5567 - val_loss: 0.6761 - val_recall: 0.1628 - val_precision: 0.7000 - val_auc: 0.6028\n",
      "Epoch 14/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6739 - recall: 0.1618 - precision: 0.4272 - auc: 0.5534 - val_loss: 0.6885 - val_recall: 0.2093 - val_precision: 0.6923 - val_auc: 0.6020\n",
      "Epoch 15/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6777 - recall: 0.1544 - precision: 0.3925 - auc: 0.5533 - val_loss: 0.6845 - val_recall: 0.0698 - val_precision: 1.0000 - val_auc: 0.6022\n",
      "Epoch 16/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6734 - recall: 0.1875 - precision: 0.4113 - auc: 0.5658 - val_loss: 0.6858 - val_recall: 0.1163 - val_precision: 0.7143 - val_auc: 0.6067\n",
      "Epoch 17/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6684 - recall: 0.2096 - precision: 0.4488 - auc: 0.5743 - val_loss: 0.6762 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6058\n",
      "Epoch 18/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6694 - recall: 0.1949 - precision: 0.4274 - auc: 0.5847 - val_loss: 0.6679 - val_recall: 0.1395 - val_precision: 0.6667 - val_auc: 0.6129\n",
      "Epoch 19/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6734 - recall: 0.2022 - precision: 0.4508 - auc: 0.5633 - val_loss: 0.6784 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6180\n",
      "Epoch 20/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6638 - recall: 0.2426 - precision: 0.4962 - auc: 0.5895 - val_loss: 0.6751 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6212\n",
      "Epoch 21/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6637 - recall: 0.2610 - precision: 0.4641 - auc: 0.6002 - val_loss: 0.6631 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6270\n",
      "Epoch 22/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6666 - recall: 0.2353 - precision: 0.4507 - auc: 0.5955 - val_loss: 0.6714 - val_recall: 0.0233 - val_precision: 1.0000 - val_auc: 0.6303\n",
      "Epoch 23/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6682 - recall: 0.2794 - precision: 0.4663 - auc: 0.5915 - val_loss: 0.6455 - val_recall: 0.3953 - val_precision: 0.7083 - val_auc: 0.6452\n",
      "Epoch 24/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6608 - recall: 0.2831 - precision: 0.4724 - auc: 0.6028 - val_loss: 0.6275 - val_recall: 0.3953 - val_precision: 0.7083 - val_auc: 0.6710\n",
      "Epoch 25/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6650 - recall: 0.2721 - precision: 0.4805 - auc: 0.6059 - val_loss: 0.6425 - val_recall: 0.0233 - val_precision: 1.0000 - val_auc: 0.7016\n",
      "Epoch 26/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6563 - recall: 0.2904 - precision: 0.5130 - auc: 0.6204 - val_loss: 0.6027 - val_recall: 0.4651 - val_precision: 0.8000 - val_auc: 0.7271\n",
      "Epoch 27/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6502 - recall: 0.3860 - precision: 0.5385 - auc: 0.6458 - val_loss: 0.6266 - val_recall: 0.2558 - val_precision: 1.0000 - val_auc: 0.7643\n",
      "Epoch 28/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6652 - recall: 0.2794 - precision: 0.4606 - auc: 0.6077 - val_loss: 0.6683 - val_recall: 0.2093 - val_precision: 0.9000 - val_auc: 0.6480\n",
      "Epoch 29/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6657 - recall: 0.2353 - precision: 0.4638 - auc: 0.5905 - val_loss: 0.6029 - val_recall: 0.5581 - val_precision: 0.7273 - val_auc: 0.8012\n",
      "Epoch 30/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6641 - recall: 0.2904 - precision: 0.4702 - auc: 0.6085 - val_loss: 0.5906 - val_recall: 0.3721 - val_precision: 0.8421 - val_auc: 0.7573\n",
      "Epoch 31/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6566 - recall: 0.3419 - precision: 0.5225 - auc: 0.6222 - val_loss: 0.6064 - val_recall: 0.3256 - val_precision: 0.9333 - val_auc: 0.8089\n",
      "Epoch 32/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6509 - recall: 0.3419 - precision: 0.4869 - auc: 0.6394 - val_loss: 0.6260 - val_recall: 0.0698 - val_precision: 1.0000 - val_auc: 0.7528\n",
      "Epoch 33/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6390 - recall: 0.3750 - precision: 0.5368 - auc: 0.6466 - val_loss: 0.5124 - val_recall: 0.6279 - val_precision: 0.7941 - val_auc: 0.8119\n",
      "Epoch 34/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6423 - recall: 0.4118 - precision: 0.5773 - auc: 0.6635 - val_loss: 10.7100 - val_recall: 0.4419 - val_precision: 0.8636 - val_auc: 0.7899\n",
      "Epoch 35/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6422 - recall: 0.3713 - precision: 0.5288 - auc: 0.6468 - val_loss: 0.5123 - val_recall: 0.7442 - val_precision: 0.7619 - val_auc: 0.8025\n",
      "Epoch 36/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6526 - recall: 0.3566 - precision: 0.5272 - auc: 0.6455 - val_loss: 0.5430 - val_recall: 0.4186 - val_precision: 0.9000 - val_auc: 0.8211\n",
      "Epoch 37/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6424 - recall: 0.3824 - precision: 0.5417 - auc: 0.6600 - val_loss: 0.6024 - val_recall: 0.7442 - val_precision: 0.7273 - val_auc: 0.8160\n",
      "Epoch 38/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6625 - recall: 0.3787 - precision: 0.5176 - auc: 0.6383 - val_loss: 0.6012 - val_recall: 0.0698 - val_precision: 1.0000 - val_auc: 0.8117\n",
      "Epoch 39/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6504 - recall: 0.3750 - precision: 0.5178 - auc: 0.6466 - val_loss: 0.6377 - val_recall: 0.0465 - val_precision: 1.0000 - val_auc: 0.7759\n",
      "Epoch 40/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6459 - recall: 0.3566 - precision: 0.5105 - auc: 0.6481 - val_loss: 0.5496 - val_recall: 0.4884 - val_precision: 0.9130 - val_auc: 0.8226\n",
      "Epoch 41/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6563 - recall: 0.3713 - precision: 0.5050 - auc: 0.6325 - val_loss: 0.5495 - val_recall: 0.4651 - val_precision: 0.8696 - val_auc: 0.8065\n",
      "Epoch 42/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6505 - recall: 0.3676 - precision: 0.5348 - auc: 0.6390 - val_loss: 0.5473 - val_recall: 0.4651 - val_precision: 0.9091 - val_auc: 0.8155\n",
      "Epoch 43/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6432 - recall: 0.4301 - precision: 0.5625 - auc: 0.6729 - val_loss: 0.5525 - val_recall: 0.7442 - val_precision: 0.7442 - val_auc: 0.8117\n",
      "Epoch 44/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6536 - recall: 0.3860 - precision: 0.5526 - auc: 0.6467 - val_loss: 0.6098 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.7794\n",
      "Epoch 45/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6300 - recall: 0.4007 - precision: 0.5590 - auc: 0.6799 - val_loss: 0.4874 - val_recall: 0.6977 - val_precision: 0.8333 - val_auc: 0.8233\n",
      "Epoch 46/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6278 - recall: 0.4449 - precision: 0.5990 - auc: 0.6803 - val_loss: 0.5345 - val_recall: 0.6047 - val_precision: 0.8966 - val_auc: 0.8160\n",
      "Epoch 47/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6454 - recall: 0.3971 - precision: 0.5870 - auc: 0.6604 - val_loss: 0.5596 - val_recall: 0.2791 - val_precision: 1.0000 - val_auc: 0.8061\n",
      "Epoch 48/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7241 - recall: 0.3346 - precision: 0.4973 - auc: 0.5737 - val_loss: 0.7041 - val_recall: 0.3721 - val_precision: 0.4706 - val_auc: 0.4372\n",
      "Epoch 49/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.7640 - recall: 0.2463 - precision: 0.3622 - auc: 0.5139 - val_loss: 0.6921 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6086\n",
      "Epoch 50/80\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6834 - recall: 0.2868 - precision: 0.4457 - auc: 0.5736 - val_loss: 0.6791 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6238\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "history=model.fit(x_new,labels,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(x_new_test,labels_test),validation_steps=35,callbacks=[early_stop],shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 45\n"
     ]
    }
   ],
   "source": [
    "val_auc_per_epoch = history.history['val_auc']\n",
    "best_epoch = val_auc_per_epoch.index(max(val_auc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5909602642059326,\n",
       " 0.5894598960876465,\n",
       " 0.5930232405662537,\n",
       " 0.4032258093357086,\n",
       " 0.5941485166549683,\n",
       " 0.5960240364074707,\n",
       " 0.5962115526199341,\n",
       " 0.5963990688323975,\n",
       " 0.5969617366790771,\n",
       " 0.5990247130393982,\n",
       " 0.5995873212814331,\n",
       " 0.6007126569747925,\n",
       " 0.6027756929397583,\n",
       " 0.6020255088806152,\n",
       " 0.6022130250930786,\n",
       " 0.6067141890525818,\n",
       " 0.6057764291763306,\n",
       " 0.6129032373428345,\n",
       " 0.6179670095443726,\n",
       " 0.6211552619934082,\n",
       " 0.6269692778587341,\n",
       " 0.6303451061248779,\n",
       " 0.6451613306999207,\n",
       " 0.6710427403450012,\n",
       " 0.7016128897666931,\n",
       " 0.7271192073822021,\n",
       " 0.764253556728363,\n",
       " 0.6479744911193848,\n",
       " 0.8012003898620605,\n",
       " 0.7573144435882568,\n",
       " 0.8088897466659546,\n",
       " 0.7528132200241089,\n",
       " 0.8118904829025269,\n",
       " 0.7899474501609802,\n",
       " 0.802513062953949,\n",
       " 0.8210802674293518,\n",
       " 0.8160164952278137,\n",
       " 0.8117029070854187,\n",
       " 0.7758814692497253,\n",
       " 0.8225806951522827,\n",
       " 0.806451678276062,\n",
       " 0.815453827381134,\n",
       " 0.8117029070854187,\n",
       " 0.7794448733329773,\n",
       " 0.8233307600021362,\n",
       " 0.8160164952278137,\n",
       " 0.8060765266418457,\n",
       " 0.4371717870235443,\n",
       " 0.6085896492004395,\n",
       " 0.6237809658050537]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_auc_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37\n",
      "(None, 9)\n",
      "(None, 9)\n",
      "229/238 [===========================>..] - ETA: 0s - loss: 0.7640 - recall: 0.3106 - precision: 0.4020 - auc: 0.5352(None, 9)\n",
      "238/238 [==============================] - 4s 6ms/step - loss: 0.7597 - recall: 0.3015 - precision: 0.4020 - auc: 0.5365 - val_loss: 0.7638 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5906\n",
      "Epoch 2/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6876 - recall: 0.2537 - precision: 0.4157 - auc: 0.5489 - val_loss: 0.6980 - val_recall: 0.3023 - val_precision: 0.7222 - val_auc: 0.5908\n",
      "Epoch 3/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6790 - recall: 0.2574 - precision: 0.4403 - auc: 0.5687 - val_loss: 0.6815 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5921\n",
      "Epoch 4/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6822 - recall: 0.1654 - precision: 0.3782 - auc: 0.5418 - val_loss: 0.6800 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5938\n",
      "Epoch 5/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6775 - recall: 0.2353 - precision: 0.4324 - auc: 0.5737 - val_loss: 0.6735 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5923\n",
      "Epoch 6/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6818 - recall: 0.1949 - precision: 0.4141 - auc: 0.5541 - val_loss: 0.6784 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5956\n",
      "Epoch 7/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6747 - recall: 0.1949 - precision: 0.4109 - auc: 0.5715 - val_loss: 0.6708 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5915\n",
      "Epoch 8/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6839 - recall: 0.2500 - precision: 0.4690 - auc: 0.5598 - val_loss: 0.6754 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5936\n",
      "Epoch 9/37\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6791 - recall: 0.1838 - precision: 0.4032 - auc: 0.5488 - val_loss: 0.6943 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5949\n",
      "Epoch 10/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6801 - recall: 0.1838 - precision: 0.3906 - auc: 0.5441 - val_loss: 0.6895 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6009\n",
      "Epoch 11/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6788 - recall: 0.1875 - precision: 0.4359 - auc: 0.5603 - val_loss: 0.6702 - val_recall: 0.3023 - val_precision: 0.7222 - val_auc: 0.5962\n",
      "Epoch 12/37\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6784 - recall: 0.2610 - precision: 0.4356 - auc: 0.5665 - val_loss: 0.6934 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5955\n",
      "Epoch 13/37\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6942 - recall: 0.2684 - precision: 0.4740 - auc: 0.5733 - val_loss: 0.6796 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6035\n",
      "Epoch 14/37\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6795 - recall: 0.2059 - precision: 0.4179 - auc: 0.5750 - val_loss: 0.6865 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5985\n",
      "Epoch 15/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6745 - recall: 0.2426 - precision: 0.4400 - auc: 0.5747 - val_loss: 0.6885 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6013\n",
      "Epoch 16/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6805 - recall: 0.1765 - precision: 0.4103 - auc: 0.5451 - val_loss: 0.7023 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6033\n",
      "Epoch 17/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6797 - recall: 0.1765 - precision: 0.4174 - auc: 0.5500 - val_loss: 0.6793 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6045\n",
      "Epoch 18/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6752 - recall: 0.2243 - precision: 0.4485 - auc: 0.5598 - val_loss: 0.6841 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6084\n",
      "Epoch 19/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6699 - recall: 0.2169 - precision: 0.4538 - auc: 0.5780 - val_loss: 0.6805 - val_recall: 0.0233 - val_precision: 1.0000 - val_auc: 0.6110\n",
      "Epoch 20/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6657 - recall: 0.2831 - precision: 0.5066 - auc: 0.6009 - val_loss: 0.6656 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6118\n",
      "Epoch 21/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6901 - recall: 0.2316 - precision: 0.4145 - auc: 0.5578 - val_loss: 0.7027 - val_recall: 0.1395 - val_precision: 0.7500 - val_auc: 0.6138\n",
      "Epoch 22/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6776 - recall: 0.2721 - precision: 0.4837 - auc: 0.5885 - val_loss: 0.7120 - val_recall: 0.6512 - val_precision: 0.4375 - val_auc: 0.6189\n",
      "Epoch 23/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6650 - recall: 0.2831 - precision: 0.4968 - auc: 0.6019 - val_loss: 0.6570 - val_recall: 0.4186 - val_precision: 0.6667 - val_auc: 0.6375\n",
      "Epoch 24/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6919 - recall: 0.2574 - precision: 0.4636 - auc: 0.5621 - val_loss: 0.6914 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6386\n",
      "Epoch 25/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6719 - recall: 0.2978 - precision: 0.4629 - auc: 0.6081 - val_loss: 0.6647 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6619\n",
      "Epoch 26/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6846 - recall: 0.2316 - precision: 0.4468 - auc: 0.5653 - val_loss: 0.6666 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.6512\n",
      "Epoch 27/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6717 - recall: 0.2794 - precision: 0.4444 - auc: 0.5982 - val_loss: 0.6488 - val_recall: 0.4186 - val_precision: 0.6923 - val_auc: 0.6482\n",
      "Epoch 28/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6615 - recall: 0.3346 - precision: 0.5084 - auc: 0.6311 - val_loss: 0.6017 - val_recall: 0.3721 - val_precision: 0.8889 - val_auc: 0.7434\n",
      "Epoch 29/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6796 - recall: 0.2610 - precision: 0.4465 - auc: 0.5729 - val_loss: 0.6450 - val_recall: 0.3488 - val_precision: 0.8333 - val_auc: 0.6941\n",
      "Epoch 30/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6596 - recall: 0.3897 - precision: 0.5354 - auc: 0.6391 - val_loss: 0.6248 - val_recall: 0.2558 - val_precision: 1.0000 - val_auc: 0.7067\n",
      "Epoch 31/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6652 - recall: 0.3051 - precision: 0.5061 - auc: 0.6159 - val_loss: 0.6648 - val_recall: 0.4651 - val_precision: 0.6897 - val_auc: 0.7204\n",
      "Epoch 32/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6698 - recall: 0.3309 - precision: 0.5056 - auc: 0.6124 - val_loss: 0.6299 - val_recall: 0.0698 - val_precision: 1.0000 - val_auc: 0.8042\n",
      "Epoch 33/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6691 - recall: 0.3676 - precision: 0.5025 - auc: 0.6209 - val_loss: 0.6531 - val_recall: 0.1395 - val_precision: 1.0000 - val_auc: 0.7830\n",
      "Epoch 34/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6680 - recall: 0.2868 - precision: 0.4382 - auc: 0.6020 - val_loss: 0.5523 - val_recall: 0.5116 - val_precision: 0.7097 - val_auc: 0.7967\n",
      "Epoch 35/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6536 - recall: 0.3419 - precision: 0.5027 - auc: 0.6361 - val_loss: 0.5495 - val_recall: 0.4651 - val_precision: 0.8696 - val_auc: 0.7982\n",
      "Epoch 36/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6622 - recall: 0.3750 - precision: 0.5025 - auc: 0.6523 - val_loss: 0.5881 - val_recall: 0.3256 - val_precision: 0.9333 - val_auc: 0.8095\n",
      "Epoch 37/37\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 0.6517 - recall: 0.3713 - precision: 0.5316 - auc: 0.6350 - val_loss: 0.5396 - val_recall: 0.5116 - val_precision: 0.7333 - val_auc: 0.7952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faa98d25dc0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel=tuner.hypermodel.build(best_hps)\n",
    "hypermodel.fit(x_new,labels,batch_size=BATCH_SIZE,epochs=37,validation_data=(x_new_test,labels_test),validation_steps=35,callbacks=[early_stop],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 9)\n",
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_IA=hypermodel.predict(x_new_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8876407e-01, 5.4320985e-01, 5.0000000e-01, ..., 0.0000000e+00,\n",
       "        7.0000000e+00, 0.0000000e+00],\n",
       "       [8.7528092e-01, 4.5679012e-01, 1.5000000e+00, ..., 1.0000000e+00,\n",
       "        4.5000000e+02, 2.0000000e+00],\n",
       "       [8.5505617e-01, 3.5291496e-01, 1.5000000e+00, ..., 1.0000000e+00,\n",
       "        4.2000000e+02, 3.0000000e+00],\n",
       "       ...,\n",
       "       [2.5056180e-01, 6.2962961e-01, 1.5000000e+00, ..., 1.0000000e+00,\n",
       "        1.0200000e+02, 3.0000000e+00],\n",
       "       [5.5730337e-01, 3.3686069e-01, 1.5000000e+00, ..., 1.0000000e+00,\n",
       "        1.7600000e+02, 0.0000000e+00],\n",
       "       [1.1235955e-01, 4.1975307e-01, 1.0000000e+00, ..., 1.0000000e+00,\n",
       "        1.5000000e+02, 3.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996437\n",
      "0.13448007\n"
     ]
    }
   ],
   "source": [
    "print(np.max(prediction_IA))\n",
    "print(np.min(prediction_IA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.ceil(np.round(np.max(prediction_IA),decimals=1)))\n",
    "print(np.floor(np.round(np.min(prediction_IA),decimals=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_IA=np.round(prediction_IA,decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_IA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion: [[97 12]\n",
      " [35 35]]\n",
      "Accuracy : 0.7374301675977654\n",
      "Precision : 0.7446808510638298\n",
      "Recall : 0.5\n",
      "AUC: 0.6949541284403671\n",
      "GINI: 0.38990825688073416\n"
     ]
    }
   ],
   "source": [
    "print('Matriz de confusion:' , confusion_matrix(np.ravel(labels_test),pred_IA))\n",
    "print('Accuracy :' , accuracy_score(np.ravel(labels_test),pred_IA))\n",
    "print('Precision :' , precision_score(np.ravel(labels_test),pred_IA))\n",
    "print('Recall :' , recall_score(np.ravel(labels_test),pred_IA))\n",
    "print('AUC:' , roc_auc_score(np.ravel(labels_test),pred_IA))\n",
    "print('GINI:' , (2*roc_auc_score(np.ravel(labels_test),pred_IA))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 9)\n",
      "(None, 9)\n",
      "(None, 9)\n",
      "(None, 9)\n",
      "(None, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 01:45:36.310345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-22 01:45:36.327754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-22 01:45:36.360465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-22 01:45:36.389764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-22 01:45:36.408132: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 9)\n",
      "(None, 9)\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(9, 1024), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4007b39a0>, 140617766566096), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1024,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe400741d90>, 140617766567056), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1024, 256), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe400754c40>, 140617766731824), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(256,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe400769b50>, 140617766732592), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(256, 256), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006ff970>, 140617766735664), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(256,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4007157f0>, 140617766248688), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(256, 128), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe40072b610>, 140617766250704), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(128,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006c5490>, 140617766248496), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(128, 64), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006d92b0>, 140617766314128), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(64,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006eb130>, 140617766314320), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(64,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006f8f70>, 140617766317680), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(64,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe40068adf0>, 140617766363376), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(64, 1), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe40069fc10>, 140617766364048), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006b4a90>, 140617766366064), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 01:45:36.950785: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-22 01:45:37.019374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-22 01:45:37.069302: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-22 01:45:37.105795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-22 01:45:37.131960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(9, 1024), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4007b39a0>, 140617766566096), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1024,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe400741d90>, 140617766567056), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1024, 256), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe400754c40>, 140617766731824), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(256,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe400769b50>, 140617766732592), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(256, 256), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006ff970>, 140617766735664), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(256,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4007157f0>, 140617766248688), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(256, 128), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe40072b610>, 140617766250704), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(128,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006c5490>, 140617766248496), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(128, 64), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006d92b0>, 140617766314128), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(64,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006eb130>, 140617766314320), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(64,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006f8f70>, 140617766317680), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(64,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe40068adf0>, 140617766363376), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(64, 1), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe40069fc10>, 140617766364048), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(1,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fe4006b4a90>, 140617766366064), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelo_IA_base4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelo_IA_base4/assets\n"
     ]
    }
   ],
   "source": [
    "hypermodel.save('modelo_IA_base4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
